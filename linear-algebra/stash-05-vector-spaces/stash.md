##### Содержание
1. Линейное пространство и сопутствующие определения
2. Линейная зависимость
3. Полные системы
4. Базис линейного пространства
5. Координатное пространство
	1. Определения
	2. Изоморфизм линейных пространств
6. Подпространства
	1. Определение
	2. Размерность пространств
	3. Аффинные подпространства
	4. Алгебра подпространств
	5. Переход к новому базису 
7. Линейные операторы


---
$$ 
\hspace{8cm}
\begin{array}{r}
\textit{"Это очень важно. Кто не поймёт — тот проиграл.”} \\
	\text{— И. В. Аржанцев}
\\[-0.8em]
\rule{7cm}{0.3pt}
\end{array}
$$
# Основные определения

> [!Info] Определение
> **Линейным** (*векторным*) **пространством** $(V, +, \times)$ над полем $P$ называется множество $V = \{v_1, v_2, \dots\}$ с определенными на нем операциями сложения $V + V \to V$ и умножения на скаляр $P \times V \to V$,  которые удовлетворяют следующим аксиомам:
> 1. Коммутативность сложения: $$\forall v_1, v_2 \in V: v_1 + v_2 = v_2 + v_1$$
> 2. Ассоциативность сложения: $$\forall v_1, v_2, v_3 \in V: (v_1 + v_2) + v_3 = v_1 + (v_2 + v_3)$$
> 3. Существует нейтральный элемент $0_v$ по сложению: $$\forall v \in V:0_v + v = v + 0_v = v$$
> 4. Существует обратный элемент $-v$ по сложению: $$\forall v \in V: v + (-v) = (-v) + v = 0_v $$
> 5. Существует нейтральный элемент $1$ по умножению на скаляр: $$\forall v \in V:1 \times v = v $$
> 6. Ассоциативность умножения на скаляр: $$\forall \lambda, \mu \in P, v \in V: (\lambda\mu)v = \lambda(\mu v)$$
> 7. Дистрибутивность умножения на скаляр относительно скалярного сложения: $$\forall \lambda, \mu \in P, v \in V: (\lambda + \mu)v = \lambda v + \mu v $$
> 8. Дистрибутивность умножения на скаляр относительно сложения: $$\forall \lambda \in P, v_1, v_2 \in V: \lambda(v_1 + v_2) = \lambda v_1 + \lambda v_2$$

> [!INFO]
> Элемент линейного пространства называется **вектором**.
> Совокупность произвольных векторов называется **системой векторов**.

### Линейные комбинации

> [!Info]
> **Линейной комбинацией** системы векторов $v_1, v_2, \dots, v_k$ на поле $P$ называется вектор вида $$\lambda_1v_1 + \lambda_2v_2+\dots+\lambda_kv_k, ~~\lambda_i \in P $$

> [!Info]
> Линейная комбинация системы из $k$ векторов называется **тривиальной**, если $\forall 1 \leq i \leq k: \lambda_i = 0$, и **нетривиальной** иначе.

---
# Линейная зависимость

> [!NOTE]
> Система векторов $v_1, v_2, \dots, v_k$ на поле $P$ называется **линейно зависимой**, если существует их нетривиальная линейная комбинация, тождественная нулевому вектору. Формально, $$\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0_v, ~\exists 1 \leq i \leq k: \lambda_i \neq 0  $$
> В противном случае, т.е. когда единственная их линейная комбинация, тождественная нулевому вектору, тривиальна, система называется **линейно независимой**. Формально, $$(\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0_v) \iff \forall 1 \leq i \leq k: \lambda_i = 0 $$

> [!Warning]
> В общем случае **не любой** вектор линейно зависимой системы можно выразить через остальные, поскольку мы требуем лишь чтобы это выполнялось хотя бы для одного из них.

> **Лемма 1**
> 
> Надсистема линейно зависимой системы векторов линейно зависима.
> 
> **Доказательство**
> 
> Рассмотрим линейно зависимую систему из $k$ векторов. По определению, $$\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0_v, \exists 1 \leq i \leq k: \lambda_i \neq 0$$
> Добавим к системе $r$ векторов. Нетрудно заметить, что если взять их в комбинацию с коэффициентами 0, то тождество сохранится, что и требовалось доказать.

> **Лемма 2**
> 
> Подсистема линейно независимой системы векторов линейно независима.
> 
> **Доказательство**
> 
> Рассмотрим линейно независимую систему векторов $X$. Если существует её линейно зависимая подсистема $R$, то $X$ является её надсистемой, а в таком случае лемма (1) говорит нам, что $X$ линейно зависима. Противоречие.

> **Теорема 1**
> 
> Система из $k$ векторов $v_1, v_2, \dots, v_k$ линейно зависима тогда и только тогда, когда хотя бы один из них является линейной комбинацией оставшихся.
> 
> **Доказательство**
> 
> *Достаточность*. Пусть $\exists i: v_i = \lambda_1v_1 + \dots + 0v_i + \dots +  \lambda_kv_k$. Тогда $$\lambda_1v_1 + \dots + \lambda_{i - 1}v_{i - 1} + (-1)v_i +  \lambda_{i + 1}v_{i + 1} + \dots + \lambda_kv_k = 0_v$$
> Поскольку коэффициент при $v_i$ равен -1, то получившаяся линейная комбинация является нетривиальной, что и требовалось доказать.
> 
> *Необходимость*. Пусть $\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0, ~ \exists 1 \leq i \leq k: \lambda_i \neq 0$. Тогда $$\begin{gathered} -\lambda_iv_i = \lambda_1v_1 + \dots + 0v_i + \dots + \lambda_kv_k \iff \\ \\ \iff v_i = \frac{\lambda_1}{-\lambda_i}v_1 + \dots + 0v_i + \frac{\lambda_k}{-\lambda_i}v_k,  \end{gathered}$$
> то есть вектор $v_i$ является линейной комбинацией оставшихся, что и требовалось доказать.

---
# Полные системы

> [!Info]
> Система векторов $v_1, v_2, \dots, v_k$ пространства $V$ называется **полной** или **порождающей**, если любой вектор из $V$ представим в виде её линейной комбинации: $$\forall v \in V~ \exists \lambda_1, \lambda_2, \dots, \lambda_k : v = \lambda_1v_1 + \lambda_2v_2 +\dots+\lambda_kv_k$$
> В противном случае система называется *неполной*. Формально, система неполна, когда $$ \exists v \in V ~ \forall \lambda_1, \lambda_2, \dots, \lambda_k : v \neq \lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k$$

> **Лемма 3**
> 
> Надсистема полной системы векторов полна.
> 
> **Доказательство**
> 
> Рассмотрим полную систему из $k$ векторов. По определению, $$\forall v \in V~ \exists \lambda_1, \lambda_2, \dots, \lambda_k : v = \lambda_1v_1 + \lambda_2v_2 +\dots+\lambda_kv_k$$
> Добавим к системе $r$ векторов. Нетрудно заметить, что если взять их в комбинацию с коэффициентами $0$, то тождество сохранится, что и требовалось доказать.

> **Лемма 4**
> 
> Подсистема неполной системы векторов неполна.
> 
> **Доказательство**
> 
> Рассмотрим произвольную неполную систему векторов $X$. Если существует её полная подсистема $R$, то $X$ является её надсистемой, а в таком случае лемма (3) говорит нам, что $X$ полна. Противоречие.

> **Лемма 5**
> 
> Исключение из системы вектора, представляющего собой линейную комбинацию остальных её векторов, не влияет на её полноту.
> 
> **Доказательство**
> 
> Рассмотрим произвольную систему из $k$ векторов.
> 
> Если она неполна, то утверждение немедленно следует из леммы (4).
> 
> Если она полна, то зафиксируем разложение произвольного вектора $v \in V$: $$v = \lambda_1v_1 + \lambda_2v_2 + \dots+\lambda_kv_k \tag{1}$$
> По утверждению леммы, найдётся номер $1 \leq i \leq k$ такой, что $$v_i = \lambda'_1v_1 +\lambda'_2v_2 + \dots + 0v_i + \dots + \lambda'_kv_k$$
> Если представить $v_i$ в таком виде, то тождество (1) принимает вид  $$\begin{gathered} v = \lambda_1v_1 + \lambda_2v_2 + \dots+ (\lambda'_1v_1 +\lambda'_2v_2 +\dots+\lambda'_kv_k) + \dots +\lambda_kv_k = \\ \\ = (\lambda_1 + \lambda'_1)v_1 + (\lambda_2+\lambda'_2)v_2 + \dots + 0v_i + \dots + (\lambda_k + \lambda'_k)v_k, \end{gathered}$$
> т.е. при исключении $v_i$ из системы $v$ всё ещё представим в виде её линейной комбинации, что и требовалось доказать.

> **Основная лемма о линейной зависимости**
> 
> Если любой вектор некоторой системы векторов $V$ размера $k$ выражается как линейная комбинация системы векторов $U$ размера $m$, то при условии $k > m$ система $V$ линейно зависима.
> 
> **Доказательство**
> 
> Рассмотрим произвольные системы $V = (v_1, v_2, \dots, v_k)$ и $U = (u_1, u_2, \dots, u_m)$, удовлетворяющие условию леммы.
> 
> По условию, $$\begin{gathered} v_1 = \mu_{11}u_1 + \mu_{21}u_2 + \dots + \mu_{m1}u_m \\ \\ v_2 = \mu_{12}u_1 + \mu_{22}u_2 + \dots + \mu_{m2}u_m \\ \\ \dots \\ \\ v_k = \mu_{1k} + \mu_{2k} + \dots + \mu_{mk}u_m \end{gathered}$$
> Рассмотрим произвольную линейную комбинацию, тождественную нулевому вектору: $$\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0_v$$
> Если разложить все векторы из $V$ по условию леммы, комбинация примет вид $$\lambda_1(\mu_{11}u_1 + \mu_{21}u_2 + \dots + \mu_{m1}u_m) + \dots + \lambda_k(\mu_{1k}u_1 + \mu_{2k} + \dots + \mu_{mk}u_m) = 0_v$$
> Перегруппировав слагаемые, получим $$(\lambda_1\mu_{11} + \lambda_{2}\mu_{12} + \dots + \lambda_k\mu_{1k})u_1 + \dots + (\lambda_1\mu_{m1} + \lambda_2\mu_{m2} + \dots + \lambda_k\mu_{mk})u_k = 0_v$$
> Заметим, что для того, чтобы комбинация была тождественна нулевому вектору, достаточно, чтобы каждый из коэффициентов был равен нулю, то есть $$\begin{cases} \lambda_1\mu_{11} + \lambda_2\mu_{12} + \dots + \lambda_k\mu_{1k} = 0 \\ \lambda_1\mu_{21} + \lambda_2\mu_{22} + \dots + \lambda_k\mu_{2k} = 0 \\ \\ ~~~~~~~~~~~~~~~~~~~~~~~~~~\dots \\ \\ \lambda_1\mu_{m1} + \lambda_2\mu_{m2} + \dots + \lambda_k\mu_{mk} = 0 \end{cases}$$
> Заметим, что получившаяся система уравнений, во-первых, однородна и, во-вторых, число неизвестных в ней превышает число уравнений. Мы знаем (как следствие из метода Гаусса), что она имеет ненулевое решение — иными словами, существуют такие $\lambda_1, \lambda_2, \dots, \lambda_k$, что $\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0_v$, причём как минимум одно из значений $\lambda_i$ отлично от $0$. Это значит, что вектора $v_1, v_2, \dots, v_k$ линейно зависимы, что и требовалось доказать.

---
## Базис

> [!INFO]
>  
> Линейно независимая полная система называется **базисом** векторного пространства.
> 
> Линейное пространство, в котором существует конечный базис, называется **конечномерным**.

> **Теорема 2**
> 
> Любой вектор линейного пространства единственным образом выражается как линейная комбинация базиса.
> 
> **Доказательство**
> 
> Рассмотрим некоторый базис $B = (v_1, v_2, \dots, v_n)$ линейного пространства $V$.
> 
> Допустим, что существует вектор $v$, представимый в виде двух различных линейных комбинаций векторов из $B$:  $$v = \lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_nv_n = \mu_1v_1 + \mu_2v_2 + \dots + \mu_nv_n, \exists 1 \leq i \leq n: \lambda_i \neq \mu_i$$
> Это тождество можно записать как $$\begin{gathered} \lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_nv_n - \mu_1v_1 - \mu_2v_2 - \dots - \mu_nv_n = 0_v \iff \\ \\ \iff (\lambda_1 - \mu_1)v_1 + (\lambda_2 - \mu_2) v_2 + \dots + (\lambda_n - \mu_n)v_n = 0_v \end{gathered}$$
> Поскольку $\exists 1 \leq i \leq n: \lambda_i \neq \mu_i$, то для данного $i$ верно, что $\lambda_i - \mu_i \neq 0$, что означает, что получившаяся линейная комбинация нетривиальна, а как следствие система $B$ линейно зависима и не является базисом. Противоречие.

> **Теорема 3**
> 
> Размеры всех базисов одного пространства равны.
> 
> **Доказательство**
> 
> Пусть $V = (v_1, v_2, \dots, v_n)$ и $U = (u_1, u_2, \dots, u_m)$ — два базиса некоторого векторного пространства такие, что $|V| = n > |U| = m$. 
> Поскольку $U$ — базис, то любой вектор из $V$ выражается как его линейная комбинация. В таком случае по основной лемме о линейной зависимости система $V$ линейно зависима, то есть не является базисом. Противоречие.

> **Лемма 6**
> 
> Из любой полной системы векторов конечномерного пространства можно выделить базис.
> 
> **Доказательство**
> 
> Рассмотрим произвольную полную систему векторов.
> 
> Если она линейно независима, то она уже является базисом.
> 
> Если она линейно зависима, то по лемме (5) мы можем исключить из неё все векторы, представимые в виде её линейных комбинаций, при этом сохранив полноту. Теорема (1) говорит нам, что в таком случае система станет линейно независимой, что и требовалось доказать.
> 
> *Следствие*. Минимальная по включению полная система является базисом. Из теоремы (3) следует, что верно также и обратное.

> **Лемма 7**
> 
> Любую линейно независимую систему векторов конечномерного пространства можно дополнить до базиса.
> 
> **Доказательство**
> 
> Рассмотрим произвольную линейно независимую систему векторов.
> 
> Если она полна, то она уже является базисом.
> 
> Если она неполна, то $$\exists v \in V ~ \forall \lambda_1, \lambda_2, \dots, \lambda_k : v \neq \lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k  $$
> Поскольку $v$ по определению не представим в виде линейной комбинации этой системы, то, по теореме (1), его добавление к системе не лишит её свойства линейной независимости. Если в результате дополнения система осталась неполной, то повторим процедуру. 
> Основная лемма о линейной зависимости говорит нам, что как только размер системы превысит размер базиса, она станет линейно зависимой. Из этого следуют два факта:
> 1. процесс непременно остановится;
> 2. поскольку на последнем шаге добавление любого из векторов к системе лишает её свойства линейной независимости, то, по теореме (1), все они выразимы через линейную комбинацию векторов этой системы, а значит, она полна.
> 
> Заметим, что мы получили конечную полную надсистему исходной линейно независимой системы, то есть базис, что и требовалось доказать.
> 
> *Следствие*. Максимальная по включению линейно независимая система является базисом. Из теоремы (3) следует, что верно также и обратное.
> 
> *Замечание*. Алгоритм действий, описанный в доказательстве, позволяет непосредственно построить базис любого конечномерного пространства.

---

# Координатное пространство

## Определения

> [!Info] Определение
> Векторное пространство $F^n$ над числовым полем $F$, элементы которого представляют собой наборы вида $\{x_1, x_2, \dots, x_n\}, x_i \in F$, называется **линейным координатным пространством**:  $$F^n = \left\{\begin{pmatrix} x_1 \\ x_2 \\ \dots \\ x_n \end{pmatrix}, x_i \in F\right\} $$
> 
> Линейное координатное пространство $\mathbb{R}^n$ над полем вещественных чисел называется *арифметическим векторным пространством*.

> [!Info] Определение
> Базис, состоящий из векторов вида $$\begin{gathered} (1, 0, 0, \dots, 0, 0) \\ (0, 1, 0, \dots, 0, 0) \\ (0, 0, 1, \dots, 0, 0) \\ \dots \\ (0, 0, 0, \dots,0,  1) \end{gathered}$$
> называется **стандартным базисом** в $\mathbb{R}^n$.

> [!Info] Определение
> Вектор-столбец $v_e = (x_1, x_2, \dots, x_n)^T \in F^n$ называется **координатным вектором** вектора $v$ в базисе $e = (e_1, e_2, \dots, e_n)$. Его элементы называются **координатами** вектора $v$ в базисе $e$.

> **Лемма**
> 
> Координаты линейной комбинации набора векторов совпадают с линейной комбинацией координат этих векторов.
> 
> **Доказательство**
> 
> Рассмотрим произвольную систему $v = \{v_1, v_2, \dots, v_k\}$ в линейном пространстве $V$ над полем $F$ и его базис $e = \{e_1, e_2, \dots, e_n\}$. Тогда произвольный вектор $v_i$ выражается через этот базис как $$v_i = \sum\limits_{j = 1}^n \alpha_{ij}e_j $$
> Тогда линейная комбинация векторов из $v$ в базисе $e$ будет иметь вид $$\lambda_1v_1 + \dots + \lambda_kv_k =\lambda_1 \sum_{j = 1}^n\alpha_{1j}e_j + \dots + \lambda_k\sum_{j = 1}^n\alpha_{kj}e_j = \sum_{j = 1}^n\lambda_1 \alpha_{1j}e_j + \dots + \sum_{j = 1}^n\lambda_k\alpha_{kj}e_j, $$
> т.е. она допускает разложение по базису с коэффициентами $\lambda_i\alpha_{ij}$, которые представляют собой линейную комбинацию координат векторов системы, что и требовалось доказать.

## Изоморфизм линейных пространств

> [!Info] Определение
> **Изоморфизмом** линейных пространств $V$ и $W$ называется биективное отображение $$\varphi: V \to W, $$
> которое, помимо прочего, *линейно*, т.е. удовлетворяет следующим свойствам:
> 1. $\varphi(x + y) = \varphi(x) + \varphi(y)$
> 2. $\varphi(\lambda x) = \lambda\varphi(x)$
> 
> Пространства, для которых существует изоморфизм, называются *изоморфными*.

> **Теорема**
> 
> Любое $n$-мерное векторное пространство $V$ над полем $F$ изоморфно $F^n$.
> 
> **Доказательство**
> 
> Рассмотрим произвольный базис $B$ пространства $V$: $$e = \{e_1, e_2, \dots, e_n\} $$
> Определим $\varphi: V \to F^n$ следующим образом: $$\varphi(v) = (x_1, x_2, \dots, x_n)^T, $$
> где $x_1, x_2, \dots, x_n$ — координаты вектора в выбранном базисе. Легко показать, что это биективное отображение.
> 
> Продемонстрируем его линейность. Пусть $v_1$ и $v_2$ раскладываются по базису как $$\begin{gathered} v_1 = a_1e_1 + a_2e_2 + \dots + a_ne_n \\ \\ v_2 = b_1e_1 + b_2e_2 + \dots + b_ne_n \end{gathered}$$
> Тогда их сумма имеет вид: $$v_1 + v_2 = (a_1 + b_1)e_1 + (a_2 + b_2)e_2 + \dots + (a_n + b_n)e_n $$
> Теперь заметим, что $$\varphi(v_1 + v_2) = \begin{pmatrix} a_1 + b_1 \\ a_2 + b_2 \\ \dots \\ a_n + b_n \end{pmatrix} = \begin{pmatrix} a_1 \\ a_2 \\ \dots \\ a_n \end{pmatrix} + \begin{pmatrix} b_1 \\ b_2 \\ \dots \\ b_n \end{pmatrix} = \varphi(v_1) + \varphi(v_2), $$
> что и требовалось доказать. Линейность относительно умножения на скаляр доказывается аналогичным способом.
> 
> *Следствие*. Из теоремы легко видеть, что любые векторные пространства одной размерности изоморфны друг другу.

---
# Подпространства

## Общие представления

> [!Info]
> Если $V$ — векторное пространство над полем $P$, то непустое множество $U \subseteq V$, замкнутое относительно операции взятия линейных комбинаций, называется **подпространством** $V$. 
> 
> Формально, $U \neq \varnothing$ — подпространство $V$, если $$\forall u_1, u_2 \in U, \lambda_1, \lambda_2 \in P: (\lambda_1u_1 + \lambda_2u_2) \in U$$
> 
> Менее формально, подпространство — это подмножество линейного пространства, само по себе являющееся линейным пространством.

> [!Info]
> Если $V$ — векторное пространство над полем $P$, $A$ — произвольное непустое подмножество $V$, то множество всех линейных комбинаций из $A$ называется **линейной оболочкой** множества $A$.
> 
> Формально, линейной оболочкой множества $A \neq \varnothing$ называется множество вида $$\left< A \right> = \{\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k ~|~\lambda_i \in P, v_i \in A \} $$

> **Лемма 8**
> 
> Линейная оболочка любого непустого подмножества линейного пространства $V$ над полем $P$ является его подпространством.
> 
> **Доказательство**
> 
> Очевидно, что линейная оболочка непустого множества непуста. Покажем, что она замкнута относительно операции взятия линейных комбинаций. Формально, мы хотим доказать, что $$\forall u_1, u_2 \in \textless A \textgreater, \lambda_1, \lambda_2 \in P: \lambda_1u_1 + \lambda_2u_2 \in \textless A \textgreater$$
> По определению, векторы $u_1$ и $u_2$ представимы в виде линейной комбинации векторов из множества $A$, то есть $$\begin{gathered} u_1 = \mu_1v_1 + \mu_2v_2 + \dots + \mu_kv_k \\ \\ u_2 = \gamma_1w_1 + \gamma_2w_2 + \dots + \gamma_nw_n  \end{gathered}~~~~~~~~~~ v_i \in A, w_i \in A, \mu_i \in P, \gamma_i \in P $$
> Подставив эти представления в исходное выражение, получим $$\lambda_1(\mu_1v_1 + \mu_2v_2 + \dots + \mu_kv_k) + \lambda_2(\gamma_1w_1 + \gamma_2w_2 + \dots + \gamma_nw_n) \in \textless A \textgreater$$
> Раскрыв скобки, получим $$\lambda_1\mu_1v_1 + \lambda_1\mu_2v_2 + \dots + \lambda_1\mu_kv_k + \lambda_2\gamma_1w_1 + \lambda_2\gamma_2w_2 + \dots + \lambda_2\gamma_nw_n, $$
> что является линейной комбинацией векторов из $A$, то есть по определению принадлежит линейной оболочке, что и требовалось доказать.

> [!Important]
> Если линейная оболочка $\textless A \textgreater$ множества $A \subseteq V$ совпадает с некоторым подпространством $U \subseteq V$, говорят, что $A$ *порождает* $U$.


## Размерность пространств

> [!Info]
> **Размерность** $\dim V$ линейного пространства $V$ определяется как:
> 1. минимальное число векторов в полной системе;
> 2. максимальное число векторов в линейно независимой системе;
> 3. размер базиса.
> 
> Эквивалентность этих определений следует из лемм (6) и (7).

> **Теорема о размерности подпространства**
> 
> Если $V$  — линейное пространство над полем $P$, $U \subseteq V$ — его произвольное подпространство, то:
> $$\dim U \leq \dim V \tag{1}$$
>    $$\dim U = \dim V \iff U = V \tag{2}$$
> 
> **Доказательство**
> 
> Пусть $v_1, v_2, \dots, v_n$ — базис в подпространстве $U$. 
> По лемме (7), его можно дополнить до базиса в $V$. Из этого непосредственно следует корректность пункта (1) теоремы.
> 
> Если $U = V$, то их базис совпадает, и утверждение $\dim U = \dim V$ очевидно.
> 
> Если $\dim U = \dim V$, то это означает, что дополнять базис $U$ до базиса $V$ не потребовалось. По определению, $U$ является линейной оболочкой векторов $v_1, v_2, \dots, v_n$. Поскольку эти же векторы являются базисом $V$, то и $V$ является их линейной оболочкой, откуда немедленно следует, что $U$ и $V$ совпадают.


## Аффинные подпространства

> [!Info] Определение
> Множество $L$, образованное из подпространства $U \subseteq V$ некоторого линейного пространства $V$ поэлементного сложения с произвольным вектором $v \in V$, называется **аффинным подпространством** или **линейным подмногообразием**: $$L = \{v + u, ~|~u \in U\} $$

## Алгебра подпространств

> [!Info] Определение
> **Пересечением** подпространств $U_1$ и $U_2$ называется множество $U_1 \cap U_2$ следующего вида: $$U_1 \cap U_2 = \{v ~|~ v \in U_1 \land v \in U_2\} $$

> **Лемма 9**
> 
> Пересечение подпространств является подпространством.
> 
> **Доказательство**
> 
> Рассмотрим $v_1, v_2 \in U_1 \cap U_2, \lambda_1, \lambda_2 \in F$. По определению, $$\begin{gathered} v_1 \in U_1 \land v_2 \in U_1 \implies \lambda_1v_1 + \lambda_2v_2 \in U_1 \\ \\ v_1 \in U_2 \land v_2 \in U_2 \implies \lambda_1v_1 + \lambda_2v_2 \in U_2, \end{gathered}$$
> откуда $\lambda_1v_1 + \lambda_2v_2 \in U_1 \cap U_2$, что и требовалось доказать.

> [!Info] Определение
> **Суммой** подпространств $U_1$ и $U_2$ называется множество $U_1 + U_2$ следующего вида: $$U_1 + U_2 = \{a + b ~|~ a \in U_1, b \in U_2\} $$

> **Лемма 10**
> 
> Сумма подпространств является подпространством.
> 
> **Доказательство**
> 
> Рассмотрим $a_1 + b_1, a_2 + b_2 \in U_1 + U_2, \lambda_1, \lambda_2 \in F$. По определению, $$\begin{gathered} \lambda_1a_1 + \lambda_2a_2 \in U_1 \\ \\ \lambda_1b_1 + \lambda_2b_2 \in U_2, \end{gathered}$$
> откуда $$\lambda_1(a_1 + b_1) + \lambda_2(a_2 + b_2) = (\lambda_1a_1 + \lambda_2a_2) + (\lambda_1b_1 + \lambda_2b_2),$$
> что по определению принадлежит $U_1 + U_2$, что и требовалось доказать.

> **Формула Грассмана**
> 
> $$\dim(U_1 + U_2) = \dim U_1 + \dim U_2 - \dim(U_1 \cap U_2) $$
> **Доказательство**
> 
> Рассмотрим базис пересечения $U_1$ и $U_2$: $$U_1 \cap U_2 = \{u_1, \dots, u_r\}, ~~ r = \dim(U_1 \cap U_2) $$
> Дополним его до базиса в $U_1$: $$Z = \{u_1, \dots, u_r, ~ v_1, \dots, v_k\}, ~~k = \dim U_1 - r $$
>  и до базиса в $U_2$: $$W = \{u_1, \dots, u_r, ~b_1, \dots, b_n\}, ~~n = \dim U_2 - r$$
>  Рассмотрим следующее множество: $$B = \{u_1, \dots, u_r, ~ v_1, \dots, v_k, ~ b_1, \dots, b_n\} $$
>  Легко показать, что $B$ порождает $U_1 + U_2$. Любой вектор $x \in U_1$ выражается через векторы $\{u_1, \dots, u_r, ~ v_1, \dots, v_k\}$, а $y \in U_2$ — через векторы $\{u_1, \dots, u_r, ~ b_1, \dots, b_n\}$, т.е. их сумму всегда можно выразить через базис $B$. 
>  
>  Покажем теперь, что векторы из $B$ линейно независимы. Рассмотрим произвольную линейную комбинацию, равную нулю: $$\sum\limits_{i = 1}^r \lambda_iu_i + \sum\limits_{i = 1}^k\alpha_iv_i + \sum\limits_{i = 1}^n\beta_ib_i = 0 \tag{1}$$
>  Перенесём последнюю сумму в правую часть: $$\sum\limits_{i = 1}^r \lambda_iu_i + \sum\limits_{i = 1}^k\alpha_iv_i = - \sum\limits_{i = 1}^n\beta_ib_i  $$
>  Здесь левая часть принадлежит $U_1$, правая — $U_2$, а значит, что вектор $v = - \sum\limits_{i = 1}^n\beta_ib_i$ принадлежит $U_1 \cap U_2$. Распишем его представление в этом базисе: $$v = \sum\limits_{i = 1}^r\xi_iu_i $$
>  Таким образом, имеем $$v - v = \sum\limits_{i = 1}^r\xi_iu_i + \sum\limits_{j = 1}^n\beta_ib_i = 0 $$
>  Поскольку при этом векторы $u_1, \dots, u_r, ~ b_1, \dots, b_n$ составляют базис в $U_2$, то имеем $\xi_i = \beta_i = 0$. Подставив это в $(1)$, получим $$\sum\limits_{i = 1}^r \lambda_iu_i + \sum\limits_{i = 1}^k\alpha_iv_i = 0  $$
>  и, поскольку $\{u_1, \dots, u_r, ~ v_1, \dots, v_k\}$ — базис в $U_1$, то имеем $\lambda_i = \alpha_i = 0$, т.е. линейная комбинация тривиальна, что и требовалось доказать.

> [!Info] Определение
> Базис линейного пространства $V$ называется **согласованным** с подпространством $U$, если $U$ является линейной оболочкой произвольных векторов из этого базиса.

> **Лемма 11**
> 
> Для любых двух подпространств $U_1$ и $U_2$ линейного пространства $V$ существует базис $V$, согласованный с каждым из них.
> 
> **Доказательство**
> 
> Легко показать, что искомый базис — это просто базис суммы, дополненный до базиса всего подпространства.

## Переход к новому базису

> [!Info] Определение
> Пусть $E = \{e_1, \dots, e_n\}$ и $E' = \{e'_1, \dots, e'_n\}$ — два произвольных базиса $n$-мерного пространства $V_n$. Широко известно, что векторы $e'_1, \dots, e'_n$ выражаются как линейная комбинация базиса $E$: $$e'_i = \alpha_{i1}e_1 + \dots + \alpha_{in}e_n$$
> Иными словами, имеем $$E' = \begin{pmatrix}\alpha_{11} & \dots & \alpha_{1n} \\ \vdots & \ddots & \vdots & \\ \alpha_{n1} & \dots & \alpha_{nn} \end{pmatrix} E$$
> Матрица $A = \{\alpha_1, \dots, \alpha_n\}$ называется **матрицей перехода** между базисами $E'$ и $E$.
> 
> При этом легко видеть, что $B^{-1}E' = E$, т.е. матрица обратного перехода — это обратная матрица перехода.

---

# Линейные операторы

> [!Info] Определение
> Отображение $A: V \to W$ между векторными пространствами $V$ и $W$, удовлетворяющее свойству линейности, т.е. такое, что $$\begin{gathered} A(a + b) = A(a) + A(b) \\ \\ A(\lambda a) = \lambda A(a) \end{gathered}$$
> называется **линейным оператором**, действующим из $V$ в $W$.

> [!Info] Определение
> **Ядром** $\ker A$ линейного оператора $A : V \to W$ называется множество всех векторов $v \in V$ таких, что $A(v) = 0$.

> [!Info] Определение
> **Образом** $\text{Im}~A$ линейного оператора $A: V \to W$ называется множество всех векторов $w \in W$ таких, что $\exists v \in V: A(v) = w$.

> **Матрица линейного оператора**
> 
> Чтобы полностью задать линейный оператор $A: V \to W$, достаточно указать, во что он переводит базисные векторы $e_i \in V$: $$A_E = \begin{pmatrix} \alpha_{11} & \dots & \alpha_{1n} \\ \vdots & \ddots & \vdots \\ \alpha_{m1} & \dots & \alpha_{mn} \end{pmatrix},$$
> где $\{\alpha_{1i}, \dots, \alpha_{mi}\}$ — координаты вектора $A(v_i)$ в базисе $E$ пространства $V$.

---