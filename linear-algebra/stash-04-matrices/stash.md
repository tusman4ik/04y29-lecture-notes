##### Содержание
0. Комбинаторный минимум
	1. Определение перестановки
	2. Симметрическая группа
	3. Циклы
	4. Деконструкция перестановок
	5. Инверсии и их свойства
1. Основные понятия
	1. Определение матрицы
	2. Классификация матриц
2. Операции над матрицами
	1. Простые операции
	2. Умножение матриц
	3. Транспонирование матриц
	4. Элементарные преобразования
3. Ранг матрицы
4. Обратная матрица
	1. Определение
	2. Алгоритм нахождения обратной матрицы
5. Определитель
	1. Определение определителя
	2. Свойства определителя
	3. Минор и алгебраическое дополнение
	4. Разложение определителя

#TODO обратная по определителю (?)

---
$$
\hspace{6cm}
\begin{array}{r}
\textit{"Абсолютно неочевидно, удивительно, но говорят,  что правда.”} \\
	\text{— И. В. Аржанцев}
\\[-0.8em]
\rule{7cm}{0.3pt}
\end{array}
$$

# Комбинаторный минимум

## Основные понятия

> [!Info]
> Произвольная биекция $\sigma: X \to X$ называется **перестановкой** на некотором конечном множестве $X$.

Перестановка традиционно представляется в виде матрицы размерностью $2 \times |X|$: $$\begin{pmatrix} x_1 & x_2 & \dots & x_n \\ \sigma(x_1) & \sigma(x_2) & \dots & \sigma(x_n) \end{pmatrix}, $$ где $n = |X|,  ~\bigcup\limits_{i = 1}^nx_i = X$. 
Иными словами, в первой строке записаны прообразы, а во второй — образы $\sigma$.

### Симметрическая группа

Рассмотрим множество $S_X$ всех перестановок на $X$ и операцию *композиции* отображений.

> **Утверждение**
> 
> $\langle S_x, \circ \rangle$ является **группой**.
> 
> **Доказательство**
> 
> 1. *Ассоциативность*
>    Ассоциативность операции композиции была доказана читателем на занятиях по дискретной математике, поэтому данный факт принимается за очевидное.
>    
> 2. *Нейтральный элемент*
>    Нейтральным элементом по операции композиции является *тождественная перестановка* $e$, которая сопоставляет элемент сам себе. Легко заметить, что в таком случае $e \circ \sigma = \sigma \circ e = \sigma$.
>    
> 3. *Обратный элемент*
>    Обратным элементом по операции композиции является *обратная перестановка* $\sigma^{-1}$ такая, что $\sigma(x) = y \implies \sigma^{-1}(y) = x$. Легко заметить, что, обратная перестановка всегда существует и единственна, а также что $(\sigma^{-1} \circ \sigma)(x) = x$.
>    
> Таким образом, $\langle S_x, \circ \rangle$ удовлетворяет всем аксиомам группы, что и требовалось доказать.

> [!Info ]
>  Группа $S_X$ всех перестановок на множестве $X$ относительно операции композиции называется **симметрической группой** или **группой перестановок**.

---
## Циклы

> [!Info]
> Перестановка $\sigma$ на множестве $X$  называется **циклом**, если существует $S = \{s_1, s_2, \dots, s_k\} \subseteq X$ такое, что: 
> 1. $\sigma(s_1) = s_2, \sigma(s_2) = s_3, \dots, \sigma(s_{k - 1}) = s_k), \sigma(s_k) = s_1$
> 2. $\forall x \in X \setminus S: \sigma(x) = x$
> 
> Иными словами, цикл переводит каждый элемент $S$ в следующий за ним (последний переходит в первый), не затрагивая остальные.
> 
> Под записью $(s_1, s_2, \dots, s_k)$ будем подразумевать цикл, действующий на соответствующем множестве $S$.
 
> [!Info]
> Цикл длины 2, т.е. перестановка, меняющая местами два произвольных элемента, называется **транспозицией**.
> Транспозицию, меняющую местами два соседних элемента, будем называть *смежной*.

###  Деконструкция перестановок

> **Лемма 1**
> 
> Любую перестановку $\sigma : X \to X$ можно единственным с точностью до порядка элементов образом представить в виде произведения независимых (т.е. поэлементно непересекающихся) циклов.
> 
> **Доказательство**
> 
> *Существование*. Рассмотрим последовательность $$a_1 \in X, a_2 = \sigma(a_1), a_3 = \sigma(a_2), \dots$$
> Поскольку множество $X$ конечно, то в этой последовательности рано или поздно начнутся повторения. Пусть $k$ — минимальный индекс такой, что $\exists j < k : a_k = a_j$, т.е. индекс первого повторяющегося элемента. Легко заметить, что в таком случае $j=1$. Если это не так, то прообразами $\sigma(a_k)$ одновременно являются $a_j$ и $a_k, a_j \neq a_k$, что противоречит условию биективности.
> Таким образом, мы получили цикл $C_1 = (a_1, a_2, \dots, a_k)$.
> Теперь, если какой-то $a' \in X$ не вошёл в $C_1$, повторим предыдущие шаги, взяв $a_1 = a'$, и получим новый цикл $C_2$. Будем проделывать эту манипуляцию до тех пор, пока всё множество не будет покрыто каким-то числом циклов. Этот процесс обязательно завершится, поскольку $X$ конечно и на каждой итерации мы покрываем циклом как минимум один элемент.
> Таким образом, мы получаем некоторое количество независимых циклов, композиция которых, по нашему определению, образует исходную перестановку.
> 
> *Единственность*. Пусть $\sigma$ представима в виде композиции циклов двумя различными способами: $$\sigma = C_1C_2\dots C_n = D_1D_2\dots D_m $$
> Рассмотрим произвольный $a \in X$. Обозначим циклы, которым он принадлежит в обоих разбиениях, соответственно $C_p$ и $D_q$. Здесь $C_{p'} = D_{q'} = \sigma(a)$, где $p'$ и $q'$ — следующие за $a$ элементы в соответствующих циклах. Повторяя эту процедуру для каждого последующего элемента, получим, что $C_p = D_q$ с точностью до порядка элементов, что и требовалось доказать.
> 
> *Замечание*. При записи последовательности в виде композиции циклов тривиальные циклы (т.е. циклы длины 1) опускаются.

> **Лемма 2**
> 
> Любой цикл $(s_1, s_2, \dots, s_k)$ можно представить в виде произведения $k-1$ транспозиций.
> 
> **Доказательство**
> 
> Покажем, что $$(s_1, s_2, \dots, s_k) = (s_1, s_2) (s_1,s_3)\dots(s_1,s_k)$$
> Элемент $s_k$ непременно перейдёт в $s_1$, поскольку никакие транспозиции, кроме $(s_1, s_k)$ не затрагивают $k$-й элемент.
> Элемент $s_1$ по аналогии непременно перейдёт в $s_2$.
> С произвольным элементом $a_i$, где $1 < i < k$, произойдёт следующее:
> 1. Перед транспозицией $(1, s_i)$ выполнится транспозиция $(1, s_{i + 1})$, в результате чего первую позицию в цикле займёт элемент $s_{i + 1}$.
> 2. В результате транспозиции $(1, s_i)$ $s_i$ примет значение первого элемента в цикле, которым на данном шаге является $s_{i + 1}$.
> 
> Так, $s_i$ непременно перейдёт в $s_{i + 1}$.
> 
> При этом элементы, не затронутые циклом, не будут затронуты ни одной из транспозиций. Все условия цикла выполняются, что и требовалось доказать. 
> 
> *Следствие*. Любую предстановку можно представить в виде произведения транспозиций.

> **Лемма 3**
> 
> Любую транспозицию $(i, j), j \geq i + 1$ можно представить в виде $2(j - i) - 1$ смежных транспозиций.
> 
> **Доказательство**
> 
> Покажем, что $$(i, j) = (i, i + 1)\dots(j - 2, j - 1)(j - 1, j)(j - 2, j - 1)\dots(i + 1, i + 2)(i, i + 1)$$
> $i$-й элемент непременно окажется на позиции $j$.
> Первые $j-i$ транспозиций будут менять его со следующим до тех пор, пока он не займёт позицию $j$, которую в дальнейшем не затронет ни одна из последующих транспозиций.
> 
> $j$-й элемент, в свою очередь, непременно окажется на позиции $i$.
> В результате первых $j-i$-й транспозиции он окажется на позиции $j-1$. Оставшиеся транспозиции будут менять его с предыдущим до тех пор, пока он не займёт позицию $i$.
> 
> С произвольным элементом с индексом $i < k < j$ произойдёт следующее:
> 1. В результате транспозиции $(k - 1, k)$ он займёт $k-1$-ю позицию.
> 2. Когда транспозиция $(k - 1, k)$ выполнится во второй раз, то он вновь займёт $k$-ю позицию.
> 
> Так, позиция $k$-го элемента не изменится. Тогда все условия транспозиции выполняются, что и требовалось доказать.

---
## Инверсии

> [!Info]
>Для произвольной перестановки $\sigma$ пара индексов $\langle i, j \rangle$ такая, что $i < j$ и $\sigma_i > \sigma_j$, называется **инверсией**.
> 
> Количество инверсий в перестановке $\sigma$ обозначается $N(\sigma)$.

> [!Info]
> **Знак** $\text{sgn}(\sigma)$ перестановки $\sigma$ определяется следующим образом: $$\text{sgn}(\sigma) = (-1)^{N(\sigma)} $$Иными словами, если число инверсий в перестановке чётно, то она имеет положительный знак, иначе — отрицательный.
> 
> Перестановки также называются *чётными* или *нечётными* в соответствии с их знаком.

### Свойства инверсий и чётности

> **Лемма 4**
> 
> Произведение на смежную транспозицию изменяет число инверсий на 1.
> 
> **Доказательство**
> 
> Рассмотрим произвольную смежную транспозицию $(i, i + 1)$.
> Если $j < i$, то верно также, что $j < i + 1$. При помещении $j$-го элемента на позицию $j + 1$ пара $(j, i)$ станет парой $(j, i + 1)$ и при этом сохранит свои свойства: она останется инверсией, если была ей, и не станет ей в противном случае. 
>
> Аналогичные рассуждения проделываются и для случая, когда $j > i + 1$. 
> Таким образом, смежная транспозиция никак не влияет на инверсии, в составе которых хотя бы один из элементов не затронут ей. Единственная пара, для которой это не выполняется — это сама пара $(i, i + 1)$. Нетрудно заметить, что если она была инверсией, то перестанет ей быть, и наоборот. В общем случае число инверсий либо уменьшится на 1, либо увеличится на 1, что и требовалось доказать.
> 
> *Замечание*. Произведение перестановки на смежную транспозицию меняет её знак.

Из этого утверждения немедленно следуют:

> **Лемма 5**
> 
> Произведение на произвольную транспозицию меняет знак перестановки.
> 
> **Доказательство**
> 
> По лемме (3), произвольная транспозиция раскладывается в $2(j - i) + 1$ смежных транспозиций. Заметим, что это число нечётно, то есть при произвольной транспозиции знак перестановки меняется некоторое нечётное число раз. Теперь удивительно заметим, что в следствие этого знак перестановки изменится.

> **Лемма 6**
> 
> Чётность цикла противоположна чётности его длины.
> 
> **Доказательство**
> 
> По лемме (1), цикл длины $k$ раскладывается в $k-1$ независимую транспозицию.
> Если мы воспринимаем цикл как результат применения этих транспозиций к тождественной перестановке, то в процессе этого её чётность изменится $k-1$ раз, то есть итоговая перестановка будет чётной, если чётно $k-1$, то есть нечётно $k$, и наоборот.

> **Теорема 1**
> 
> $\text{sgn}(\sigma \circ \tau) = \text{sgn}(\sigma) \times \text{sgn}(\tau)$
> 
> **Доказательство**
> 
> Это немедленно следует из лемм (1), (2) и (5).
> Мы можем представить $\sigma$ и $\tau$ как произведение $n$ и $m$ транспозиций соответственно. В таком случае их композиция представляется как последовательное произведение $n + m$ транспозиций. Заметим, что $(-1)^{n + m} = (-1)^n \times (-1)^m$, что и требовалось доказать.
> 
> *Следствие*. $\text{sgn}(\sigma) = \text{sgn}(\sigma^{-1})$
> По только что доказанной теореме, $\text{sgn}(\sigma) \times \text{sgn}(\sigma^{-1}) = \text{sgn}(\sigma \circ \sigma^{-1}) = \text{sgn}(e) = 1$.

---

# Основные понятия

> [!Info]
> **Матрица** $A$ размера $m \times n$ (говорят, что $\dim A = m\times n$ — *размерность* матрицы) над кольцом $R$ — совокупность элементов из $R$, упорядоченных в виде прямоугольной таблицы, состоящей из $m$ строк и $n$ столбцов. Элемент на пересечении $i$-й строки и $j$-го столбца матрицы обозначается $a_{ij}:$
> 
> $$A_{m, n} = \begin{pmatrix} a_{11} & a_{12} &\dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \dots & a_{mn}\end{pmatrix} $$
> 
> Если не заявлено обратного, то в дальнейшем мы будем подразумевать, что  $R$ — это ассоциативное кольцо с единицей.

### Классификация матриц по структуре

Зададим произвольное кольцо $R$, где:
- $0$ — нейтральный элемент для $\langle R, +\rangle$
- $1$ — нейтральный элемент для $\langle R, \times \rangle$

> **Квадратные матрицы**
> 
> Если для некоторой матрицы $A_{m \times n}$ справедливо, что $m = n$, то она называется *квадратной*. Число $n$ строк и столбцов такой матрицы называется её *порядком*.
> 
> У квадратной матрицы выделяют *главную* и *побочную* диагонали. Для любого $a_{ij}$ верно, что $j=i$, если он лежит на главной диагонали, и $j=n-i+1$, если он лежит на побочной диагонали:
> ![[Drawing 2025-10-15 19.38.43.excalidraw.png|500]]
> Сумма элементов на главной диагонали квадратной матрицы называется её **следом** и обозначается $\text{tr}~A$.

>  **Треугольные матрицы**
>  
>  Если для некоторой квадратной матрицы $A$ над $R$ справедливо, что:
>  1. $(i > j) \implies a_{ij} = 0$, т.е. все элементы ниже главной диагонали равны $0$, то она называется *верхней треугольной*;
>  2. $(i < j) \implies a_{ij} = 0$, т.е. все элементы выше главной диагонали равны , то она называется *нижней треугольной*:
>  
>  ![[Drawing 2025-10-15 22.52.22.excalidraw.png|500]]
>  
>  При аналогичном расположении элементов относительно побочной диагонали матрица будет называться *правой* или *левой треугольной*.

> **Диагональные матрицы**
> 
> Если для некоторой квадратной матрицы $A$ над $R$ справедливо, что $i \neq j \implies a_{ij} = 0$, то она называется *диагональной*:
> ![[Drawing 2025-10-15 22.57.40.excalidraw.png|500]]

> **Скалярные матрицы**
> 
> Если для некоторой диагональной матрицы $A$ справедливо, что $a_{11} = a_{22} = \dots = a_{nn} = \lambda$, то она называется *скалярной*:
> ![[Drawing 2025-10-15 23.00.21.excalidraw.png|500]]

> **Единичная матрица**
> 
> Если для некоторой скалярной матрицы $A$ справедливо, что $a_{11} = a_{22} = \dots = a_{nn} = 1$, то она называется *единичной*:
> 
> ![[Drawing 2025-10-15 23.04.11.excalidraw.png|500]]

> **Нулевая матрица**
> 
> Если для некоторой матрицы $O = \{o_{ij}\}_{m \times n}$ справедливо, что $o_{ij} = 0$, то она называется *нулевой*:
> ![[Drawing 2025-10-16 00.53.42.excalidraw.png|500]]

> **Вектор-матрицы**
> 
> Если для некоторой матрицы $A_{m \times n}$ справедливо, что $m = 1$, то она называется *вектор-строкой*. Если $n=1$, то такая матрица называется *вектор-столбцом*:
> 
> ![[Drawing 2025-10-16 01.10.31.excalidraw.png|500]]

> **Ступенчатая матрица**
> 
> Будем называть первый ненулевой элемент строки её *лидером*.
> Если для некоторой матрицы $A_{m \times n}$ верно, что номера лидеров её ненулевых строк образуют строго возрастающую последовательность, а также все её нулевые строки идут после всех ненулевых, то она называется *ступенчатой*:
> 
> ![[Drawing 2025-11-16 20.22.22.excalidraw.png]]

> **Улучшенная ступенчатая матрица**
> 
> Если для некоторой ступенчатой матрицы $A_{m \times n}$ верно, что лидеры всех ненулевых её строк равны $1$, причём каждый лидер является единственным ненулевым элементом своего столбца, то она называется *улучшенной*:
> ![[Drawing 2025-11-16 20.55.15.excalidraw.png]]

> **Строго ступенчатая матрица**
> 
> Если для некоторой ступенчатой матрицы $A_{m \times n}$ верно, что число её столбцов равно числу её ненулевых строк, то она называется *строго ступенчатой*:
> 
> ![[Drawing 2025-11-17 18.04.35.excalidraw.png]]
> 
---
# Операции над матрицами

## Простые линейные операции

### Равенство

> [!Info]
> Две матрицы $A$ и $B$ называются **равными** тогда и только тогда, когда $\dim A = \dim B = m \times n$ и $\forall 1 \leq i \leq m, 1 \leq j \leq n : a_{ij} = b_{ij}$. 
> 

### Сложение

> [!Info]
> **Суммой** матриц $A_ = (a_{ij})_{m \times p}$ и $B = (b_{ij})_{p \times k}$  называется такая матрица $C_{m\times n}$, что $$c_{ij} = a_{ij} + b_{ij}$$

> [!Warning]
> Операция сложения определена только для матриц одинаковой размерности.

#### Свойства

> **Коммутативность**
> 
> Для произвольных матриц $A = (a_{ij})_{m \times n}$ и $B = (b_{ij})_{m \times n}$ верно, что $A + B = B + A$.
> 
> **Доказательство**
> 
> Пусть $A + B = D = (d_{ij})_{m \times n}, B + A = E = (e_{ij})_{m \times n}$. 
> Поскольку матрицы определены на кольце, то операция сложения коммутативна. Тогда: $$\begin{gathered} d_{ij} = a_{ij} + b_{ij} = b_{ij} + a_{ij} = e_{ij},\end{gathered}$$ что и требовалось доказать.

> **Ассоциативность**
> 
> Для произвольных матриц $A = (a_{ij})_{m \times n}, B = (b_{ij})_{m \times n}$ и $C = (c_{ij})_{m \times n}$ верно, что $A + (B + C) = (A + B) + C$.
> 
> **Доказательство**
> 
> Пусть $A + (B + C) = D = (d_{ij})_{m \times n}, (A + B) + C = E = (e_{ij})_{m \times n}$. 
> Поскольку матрицы определены на кольце, то операция сложения ассоциативна. Тогда: $$\begin{gathered} d_{ij} = a_{ij} + (b_{ij} + c_{ij}) = (a_{ij} + b_{ij}) + c_{ij} = e_{ij}\end{gathered},$$
> что и требовалось доказать.

> **Нейтральный элемент**
> 
> Для произвольной матрицы $A = (a_{ij})_{m \times n}$ и нулевой матрицы $O = (o_{ij})_{m \times n}$ верно, что $A + O = A$.
> 
> **Доказательство**
> 
> Пусть $A + O = C = (c_{ij})_{m \times n}$.
> По определению нулевой матрицы, $o_{ij}$ является нейтральным элементом по сложению. Тогда: $$ c_{ij} = a_{ij} + 0 = a_{ij}, $$
> что и требовалось доказать.

> **Обратный элемент**
> 
> Для произвольной матрицы $A = (a_{ij})_{m \times n}$ существует матрица $-A = (-a_{ij})_{m \times n}$, причем $A + (-A) = O$.
> 
> **Доказательство**
> 
> Пусть $A + (-A) = C = (c_{ij})_{m \times n}$.
> Поскольку матрицы определены на кольце, то для произвольного $a \in R$ найдётся $-a \in R$ такой, что $a + (-a) = 0$, что значит, что мы всегда можем построить $-A$. Тогда: $$c_{ij} = a_{ij} + -a_{ij} = 0 = o_{ij}, $$
> что и требовалось доказать.

## Умножение матриц

> [!Info]
> **Произведением** матриц $A = (a_{ij})_{m \times p}$ и $B = (b_{ij})_{p \times k}$ называется такая матрица $C = (c_{ij})_{m\times n}$, что $$c_{ij} = \sum\limits_{k = 1}^p a_{ik}b_{kj} $$

В развёрнутом виде произведение матриц представляется следующим образом:
$$
\begin{gathered} 
\begin{pmatrix} 
a_{11} & \dots & a_{1n} \\ 
\vdots & \ddots & \vdots \\ 
a_{n1} & \dots & a_{nn} 
\end{pmatrix} 
\times 
\begin{pmatrix} 
b_{11} & \dots & b_{1n} \\ 
\vdots & \ddots & \vdots \\ 
b_{n1} & \dots & b_{nn}
\end{pmatrix}
= \\\\ =
\begin{pmatrix} 
a_{11}b_{11} + a_{12}b_{21}+\dots+a_{1n}b_{n1} & \dots & a_{11}b_{1n} + a_{12}b_{2n} +\dots+a_{1n}b_{nn} \\
\vdots & \ \ddots & \vdots \\
a_{n1}b_{11}+a_{n2}+b_{21}+\dots+a_{nn}b_{n1} & \dots & a_{n1}b_{1n} + a_{n2}b_{2n}+\dots+a_{nn}b_{nn}
\end{pmatrix} 
\end{gathered}
$$
Менее формально, умножение матриц производится по принципу *"строка на столбец"*, т.е. элемент $c_{ij}$ произведения $C=A\times B$ представляет собой сумму произведений элементов на соответствующей позиции в $i$-й строке матрицы $A$ и на элементы на той же позиции в $j$-м столбце матрицы $B.$

> [!Warning]
> Операция умножения определена тогда и только тогда, когда число столбцов первой матрицы равно числу строк второй матрицы — в таком случае их называют *согласованными*.

#### Свойства

> **Некоммутативность**
> 
> Существуют такие матрицы $A = (a_{ij})_{m\times p}, B = (b_{ij})_{p \times n}$, что $A\times B \neq B\times A$.
> 
> **Доказательство**
> 
> Пусть $A = \begin{pmatrix} 2 & 0 \\ 0 & 3 \end{pmatrix}$, $B = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}$, тогда: $$\begin{gathered} A \times B =\begin{pmatrix} 2\cdot1+0\cdot 1 & 2\cdot 1 + 0\cdot 1 \\ 0 \cdot 1 + 3 \cdot 1 & 0 \cdot 1 + 3 \cdot 1 \end{pmatrix} = \begin{pmatrix} 2 & 2 \\ 3 & 3 \end{pmatrix} \\ \\ B \times A =  \begin{pmatrix} 1 \cdot 2 + 1 \cdot 0 & 1 \cdot 0 + 1 \cdot 3 \\ 1 \cdot 2 + 1 \cdot 0 & 1 \cdot 0 + 1 \cdot 3 \end{pmatrix} = \begin{pmatrix} 2 & 3 \\ 2 & 3 \\ \end{pmatrix}, \end{gathered} $$то есть $A \times B \neq B \times A$, что и требовалось доказать.

> **Ассоциативность**
> 
> Для произвольных матриц $A = (a_{ij})_{m\times p}, B = (b_{ij})_{p \times l}, C = (c_{ij})_{l \times n}$ верно, что $A \times (B \times C) = (A \times B) \times C$.
> 
> **Доказательство**
> 
> Пусть $(A \times B) \times C = D = (d_{ij})_{m \times n}, A \times (B \times C) = F = (f_{ij})_{m \times n}$.
> Поскольку матрицы определены на кольце, то операция умножения ассоциативна. Тогда: $$\begin{gathered} d_{ij} = \sum\limits_{k = 0}^l(A\times B)_{ik} c_{kj} = \sum\limits_{k=0}^l\sum\limits_{r=0}^pa_{ir}b_{rk}c_{kj} \\ \\ f_{ij} = \sum\limits_{r = 0}^p a_{ir}(B \times C)_{rj} = \sum\limits_{r = 0}^pa_{ir}\sum\limits_{k = 0}^lb_{rk}c_{kj} = \sum\limits_{r = 0}^p\sum\limits_{k = 0}^la_{ir}b_{rk}c_{kj},\end{gathered}$$ то есть $D = F$, что и требовалось доказать.

> **Дистрибутивность относительно сложения**
> 
> *Леавая*: для произвольных матриц $A = (a_{ij})_{m\times p}, B = (b_{ij})_{p \times n}, C = (c_{ij})_{p \times n}$ верно, что $A \times (B + C) = A \times B+  A \times C$.
> 
> **Доказательство**
> 
> Пусть $A \times (B + C) = D = (d_{ij})_{m \times n}, A \times B + A \times C = F = (f_{ij})_{m \times n}$. 
> Поскольку матрицы определены на кольце, то операция умножения дистрибутивна относительно операции сложения. Тогда: $$\begin{gathered} d_{ij} = \sum\limits_{k = 0}^pa_{ik}(B+C)_{kj} = \sum\limits_{k=0}^pa_{ik}(b_{kj}+c_{kj})=\sum\limits_{k = 0}^pa_{ik}b_{kj} + a_{ik}c_{kj} \end{gathered}$$
> В то же время, $$f_{ij} = \sum_{k = 0}^pa_{ik}b_{kj} + \sum\limits_{l = 0}^pa_{il}c_{lj} = \sum\limits_{k=l=0}^p a_{ik}b_{kj} + a_{il}c_{lj} = \sum\limits_{k = 0}^pa_{ik}b_{kj} + a_{ik}c_{kj}, $$
> то есть $D = F$, что и требовалось доказать.
> 
> Справедливость *правой* дистрибутивности доказывается по аналогии.

> **Нейтральный элемент**
> 
> Для произвольной матрицы $A = (a_{ij})_{m \times n}$ верно, что:
> 1. $A \times E_{n} = A$
> 2. $E_m \times A = A$
> 
> **Доказательство** (1)
> 
> Пусть $A \times E_n = D = (d_{ij})_{m\times n}$. Тогда: $$d_{ij} = \sum\limits_{k = 0}^n a_{ik}e_{kj} \overset{def}{=} \sum\limits_{k = 0}^n\begin{cases} a_{ik} \times 0, j \neq k \\ a_{ik} \times 1, j = k\end{cases} = a_{ij},$$ что и требовалось доказать.
> 
> Справедливость пункта (2) доказывается по аналогии.

### Умножение на скаляр

Частный случай умножения матриц — умножение на *скалярную матрицу*. В таком случае второй множитель условно записывают как единственный элемент $\lambda$, а не как матрицу, при этом подразумевается, что она всегда согласована с первым множителем.

Нетрудно заметить, что если $A \times \lambda = C = (c_{ij})$, то $c_{ij} = \lambda \times a_{ij}$: $$ A\times\lambda = \begin{pmatrix} \lambda \times a_{11} & \lambda \times a_{12} & \dots & \lambda \times a_{1n} \\ \lambda \times a_{21} & \lambda \times a_{22} & \dots & \lambda \times a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ \lambda \times a_{n1} & \lambda \times a_{n2} & \dots & \lambda \times a_{nn}\end{pmatrix}$$
Доказательство этого факта аналогично приведенному выше доказательству (1) существования правого нейтрального элемента по умножению.

## Транспонирование

> [!Info]
> **Транспонированием** называется переход от произвольной матрицы $A = (a_{ij})_{m \times n}$ к матрице $A^T = (a^T_{ij})_{n \times m}$  такой, что $$a^T_{ij} = a_{ji} $$

В развернутом виде транспонирование матриц представляется следующим образом:

$$A = \begin{pmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23}\end{pmatrix} ~~~~~~~ A^T = \begin{pmatrix} a_{11} & a_{21} \\ a_{12} & a_{22} \\ a_{13} & a_{23}\end{pmatrix}$$
Менее формально, при транспонировании каждая строка (столбец) исходной матрицы становится соответствующим столбцом (строкой) результирующей.

#### Свойства

> **Инволютивность**
> 
> Для произвольной матрицы $A = (a_{ij})_{m \times n}$ верно, что $(A^T)^T = A$, т.е. транспонирование является *инволюцией*.
> 
> **Доказательство**
> 
> Пусть $A^T = D = (d_{ij})_{n \times m}, (A^T)^T = D^T = F = (f_{ij})_{m \times n}$. Тогда: $$f_{ij} = d_{ji} = a_{ij}, $$
> что и требовалось доказать.

> **Дистрибутивность относительно сложения**
> 
> Для произвольных матриц $A = (a_{ij})_{m \times n}$ и $B = (b_{ij})_{m \times n}$ верно, что $(A + B)^T = A^T + B^T$.
> 
> **Доказательство**
> 
> Пусть $(A+B)^T = D = (d_{ij})_{n \times m}, A^T + B^T = F = (f_{ij})_{n \times m}$. Тогда: $$\begin{gathered} d_{ij} = (A + B)_{ji} = a_{ji} + b_{ji} = f_{ij} \end{gathered},$$ что и требовалось доказать.

> **Дистрибутивность относительно умножения**
> 
> Для произвольных матриц $A = (a_{ij})_{m \times p}$ и $B = (b_{ij})_{p \times n}$ верно, что $(A \times B)^T = B^T\times A^T$.
> 
> **Доказательство**
> 
> Пусть $(A \times B)^T = D = (d_{ij})_{m \times n}, B^T \times A^T = F = (f_{ij})_{m \times n}$. Тогда: $$\begin{gathered} d_{ij} = (A \times B)_{ji} =  \sum_{k = 0}^pa_{jk} \times b_{ki} \\ \\ f_{ij} = \sum\limits_{k = 0}^n (B^T)_{ik} \times (A^T)_{kj} = \sum\limits_{k = 0}^n b_{ki} \times a_{jk}, \end{gathered}$$ то есть $D = F$, что и требовалось доказать.

> [!Info]
> Если для некоторой матрицы $A$ выполняется $A^T = A$, то она называется **симметричной**.

> [!Info]
> Если для некоторой матрицы $A$ выполняется $A^T = -A$, то она называется **кососимметричной**.

## Элементарные преобразования

> [!Info]
> **Элементарными преобразованиями** называются следующие манипуляции над матрицей:
> 1. прибавление к произвольной строке другой, умноженной на константу;
> 2. перестановка местами двух строк;
> 3. умножение строки на ненулевую константу.
> 
> Тривиальный, но важный факт — элементарные преобразования *обратимы*!

> **Теорема 2**
> 
> Путём элементарных преобразований любую матрицу можно привести к ступенчатому виду.
> 
> **Доказательство**
> 
> В качестве доказательства приведём алгоритм преобразования:
> 1. Если матрица нулевая, она уже имеет ступенчатый вид.
> 2. Иначе найдём первый её столбец, содержащий ненулевой элемент (пусть он имеет номер $j$) и преобразованием второго типа переместим любую из строк, содержащих такой элемент, на первую позицию. Он станет лидером первой строки.
> 3. Преобразованиями первого типа сделаем все элементы ниже лидера равными $0$.
> 4. Исключим из рассмотрения все столбцы до $j+1$-го и все строки до второй, и повторим процесс для новой матрицы.
> 
> Корректность алгоритма читателю предлагается оценить самостоятельно.

> **Дополнение к теореме 2**
> 
> Путем элементарных преобразований любую ступенчатную матрицу можно привести к улучшенному ступенчатому виду.
> 
> **Доказательство**
> 
> В качестве доказательства приведём алгоритм преобразования:
> 1. Преобразованиями третьего типа сделаем всех лидеров равными $1$.
> 2. Начиная с последней ненулевой строки,  преобразованиями второго типа сделаем все элементы выше соответствующего лидера равными $0$.
> 
> Корректность алгоритма читателю предлагается оценить самостоятельно. 

С каждым из элементарных преобразований можно связать соответствующую *элементарную матрицу*:

> [!col]
> **Элементарная матрица первого типа** $U_\lambda^{ij}$ получается из единичной путём применения первого элементарного преобразования
> 
> $\begin{pmatrix} 1 & 0 & 0 & \dots & 0 \\ 0 & 1 & 0 & \dots & 0 \\ \lambda & 0 & 1 & \dots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \dots & 1 \end{pmatrix}$

> [!col]
> **Элементарная матрица второго типа** $U_{ij}$ получается из единичной путём применения второго элементарного преобразования
> 
> $\begin{pmatrix} 1 & 0 & 0 & \dots & 0 \\ 0 & 0 & 1 & \dots & 0 \\ 0 & 1 & 0 & \dots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \dots & 1 \end{pmatrix}$

> [!col]
> **Элементарная матрица третьего типа** $U_{i}^\lambda$ получается из единичной путём применения третьего элементарного преобразования
> 
> $\begin{pmatrix} 1 & 0 & 0 & \dots & 0 \\ 0 & \lambda & 0 & \dots & 0 \\ 0 & 0 & 1 & \dots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \dots & 1 \end{pmatrix}$

Можно показать, что при умножении на каждую из элементарных матриц слева происходит соответствующее элементарное преобразование строк, а при умножении справа — столбцов. #TODO по-хорошему пруфнуть бы

---

# Ранг матрицы

> [!Info] Определение
> **Строчный ранг** $\text{rk}~A$ матрицы $A$ равен размерности линейной оболочки её строк как векторов или, иначе, максимальному числу линейно независимых её строк.
> 
> Аналогичным образом определяется *столбцовый ранг* матрицы. Оба этих явления называют просто **рангом матрицы**.

> **Лемма 7**
> 
> Элементарные преобразования не изменяют ранг матрицы.
> 
> **Доказательство**
> 
> Рассмотрим набор $v_1, v_2, \dots, v_n$ строк некоторой матрицы $A$.
> Если набор $v'_1, v'_2, \dots, v'_n$ получен из $v_1, v_2, \dots, v_n$ элементарными преобразованиями, то он представляет собой линейную комбинацию исходной системы векторов. Применяя обратные элементарные преобразования, получим, что $v_1, v_2, \dots, v_n$ — линейная комбинация $v'_1, v'_2, \dots, v'_n$. Легко заметить, что тогда линейные оболочки этих систем совпадут, равно как и их ранги.

> **Лемма 8**
> 
> Строчный ранг матрицы равен числу ненулевых строк в её ступенчатом виде.
> 
> **Доказательство**
> 
> Поскольку элементарные преобразования не изменяют ранг матрицы, будем считать, что она уже ступенчата. Пусть $v_1, v_2, \dots, v_k$ — её ненулевые строки. Рассмотрим их нулевую линейную комбинацию: $$\lambda_1v_1 + \lambda_2v_2 + \dots + \lambda_kv_k = 0$$
> Пусть также $i_1, i_2, \dots, i_k$ — номера столбцов, в которых стоят лидеры строк.
> Докажем по индукции, что $\forall 1 \leq i \leq k: \lambda_i = 0$.
> 
> *База*. $i_1$-я координата в результирующем векторе равна $\lambda_1v_{1i_1}$, откуда немедленно $\lambda_1 = 0$.
> 
> *Переход*. Пусть предположение верно для $n < k$. Покажем, что тогда оно также верно для $n = k$.
> Легко видеть, что $i_n$-я координата в результирующем векторе равна $\sum\limits_{j=1}^n \lambda_j v_{ji_j}$. Поскольку $\forall i < n: \lambda_i = 0$, то $i_n$-я координата равна $\lambda_n v_{ni_n}$, откуда немедленно $\lambda_n = 0$.
> 
> Таким образом, векторы $v_1, v_2, \dots, v_k$ линейно независимы, что и требовалось доказать.

> **Лемма 9**
> 
> Элементарные преобразования строк матрицы $A$ не изменяют линейных соотношений между столбцами.
> 
> **Доказательство**
> 
> Если столбцы $w_1, w_2, \dots, w_n$ матрицы $A$ связаны линейным соотношением $$\lambda_1w_1 + \lambda_2w_2 + \dots + \lambda_nw_n = 0,$$
> то они являются решением однородной системы с матрицей коэффициентов $A$: $$\begin{cases} \lambda_1a_{11} + \lambda_2w_{12} + \dots + \lambda_n w_{1n} = 0 \\ \\ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\dots \\ \\ \lambda_1a_{m1} + \lambda_2w_{m2} + \dots + \lambda_nw_{mn} = 0\end{cases}$$
> Как мы знаем, элементарные преобразования порождают равносильные системы, а значит, что они сохраняют линейные соотношения между столбцами, что и требовалось доказать.
> 
> *Следствие*. Элементарные преобразования строк не влияют на линейную зависимость столбцов.

> **Лемма 10**
> 
> Столбцы, содержащие лидеры строк ступенчатой матрицы, образуют максимальное линейно независимое подмножество всех её столбцов.
> 
> **Доказательство**
> 
> Можно считать, что матрица имеет улучшенный ступенчатый вид, поскольку переход к нему также происходит при помощи элементарных преобразований.
> 
> Пусть $i_1, i_2, \dots, i_k$ — номера столбцов, содержащих лидеры строк. Легко заметить, что они образуют стандартный базис в пространстве $\mathbb{R}^k$. Мы знаем, что вектора стандартного базиса линейно независимы, причем, согласно основной лемме о линейной зависимости, его нельзя дополнить, сохранив линейную независимость системы. Таким образом, соответствующие столбцы действительно образуют максимальную по включению линейно независимую систему, что и требовалось доказать.

> **Теорема 3**
> 
> Строчный и столбцовый ранги матрицы совпадают.
> 
> **Доказательство**
> 
> Приведём матрицу к ступенчатому виду. Согласно лемме (7), это не изменит ни строчный, ни столбцовый ранг.
> Строчный ранг после этого будет равен числу ненулевых строк (лемма 8), а столбцовый — числу столбцов с лидерами строк (лемма 10). Легко заметить, что эти два значения равны. 

> [!Info] Определение
> Квадратная матрица, ранг которой меньше её размерности, называется **вырожденной** или **сингулярной**.

> **Лемма 11**
> 
> Ранг произведения матриц $A$ и $B$ не превосходит $\min\{\text{rk}~A, \text{rk}~B\}$.
> 
> **Доказательство**
> 
> Произведение $A \times B$ имеет вид: $$\begin{gathered} A\times B = \begin{pmatrix}a_{11} & \dots & a_{1k} \\ \vdots & \ddots & \vdots \\ a_{m1} & \dots & a_{mk} \end{pmatrix} \times \begin{pmatrix}b_{11} & \dots & b_{1n} \\ \vdots & \ddots & \vdots \\ b_{k1} & \dots & b_{kn} \end{pmatrix} = \\ \\ = \begin{pmatrix} b_{11} \begin{pmatrix} a_{11} \\ \vdots \\ a_{m1} \end{pmatrix} + \dots + b_{k1}\begin{pmatrix} a_{1n} \\ \vdots \\ a_{mn} \end{pmatrix}, \dots, b_{1n} \begin{pmatrix} a_{11} \\ \vdots \\ a_{m1} \end{pmatrix} + \dots + b_{kn}\begin{pmatrix} a_{1n} \\ \vdots \\ a_{mn} \end{pmatrix}    \end{pmatrix}\end{gathered}$$
> Заметим, что все столбцы матрицы произведения являются линейной комбинацией столбцов матрицы $A$, откуда немедленно следует, что линейная оболочка столбцов $AB$ является подмножеством линейной оболочки столбцов $A$, откуда $\text{rk}~AB \leq \text{rk}~A$. Неравенство $\text{rk}~AB \leq B$ получается аналогичным разложением по строкам.


---

# Обратная матрица

## Определение

> [!Info] Определение
> Матрица $A^{-1}$ называется **обратной** к матрице $A$, если $AA^{-1} = A^{-1}A = E$.
> 
> Отсюда сразу легко видеть, что только квадратные матрицы имеют квадратные.

> **Лемма 12**
> 
> Если обратная матрица существует, она единственна.
> 
> **Доказательство**
> 
> Допустим, $B = A^{-1}, C = A^{-1}, B \neq C$. Тогда имеем: $$(BA)C = B(AC) \iff EC = BE \iff B = C,$$
> что противоречит предположению.

> **Лемма 13**
> 
> Если к матрицам $A$ и $B$ размера $m \times n$ существуют обратные матрицы $A^{-1}$ и $B^{-1}$ соответственно, то существует и обратная к их произведению матрица $(AB)^{-1}$, причем верно, что $(AB)^{-1} = B^{-1}A^{-1}$.
> 
> **Доказательство**
> 
> Легко показать, что $$\begin{gathered} (AB)(B^{-1}A^{-1}) = A(BB^{-1})A^{-1} = AEA^{-1} = AA^{-1} = E \\ \\ (B^{-1}A^{-1})(AB) = B^{-1}(A^{-1}A)B = B^{-1}EB = B^{-1}B = E, \end{gathered}$$
> что и требовалось доказать.

## Алгоритм нахождения обратной матрицы

Алгоритм нахождения обратной матрицы при помощи элементарных преобразований заключается в следующем:

> **Шаг 1**
> 
> Необходимо дополнить исходную матрицу единичной: $$\left(\begin{array}{cccc|cccc} a_{11} & a_{12} & \dots & a_{1n} & 1 & 0 & \dots & 0 \\ a_{21} & a_{22} & \dots & a_{2n} & 0 & 1 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \dots & a_{mn} & 0 & 0 & \dots &1 \end{array}\right) $$

> **Шаг 2**
> 
> Необходимо при помощи элементарных преобразований привести исходную матрицу к единичной, проделывая при этом все преобразования также и над присоединённой: 
> $$\left(\begin{array}{cccc|cccc} 1 & 0 & \dots & 0 & b_{11} & b_{12} & \dots & b_{1n} \\ 0 & 1 & \dots & 0 & b_{21} & b_{22} & \dots & b_{2n} \\ \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & 1 & b_{m1} & b_{m2} & \dots & b_{mn} \end{array}\right)$$

> **Шаг 3**
> 
> Если привести исходную матрицу к единичной невозможно, обратной матрицы не существует. В противном случае матрица $B$, получившаяся в результате элементарных преобразований над присоединённой, и будет являться обратной.

> **Доказательство**
> 
> Если преобразования успешны, то, по определению, имеем: $$U_1U_2\dots U_kA = E $$
> Заметим, что $$\begin{gathered} \left( U_1^{-1}U_2^{-1}\dots U_k^{-1} \right)\left(U_1U_2\dots U_kA\right) = \left( U_1^{-1}U_2^{-1}\dots U_k^{-1} \right)E \iff \\ \\ \iff A =U_1^{-1}U_2^{-1}\dots U_{k}^{-1} \iff \\ \\ \stackrel{\text{лемма 13}}\iff A^{-1} = U_kU_{k-1} \dots U_1 = B, \end{gathered}$$
> т.е. $B$ действительно является обратной к $A$.
> 
> Преобразования провести не удастся лишь в случае, если ступенчатый вид матрицы не строго ступенчатый. Это означает, что (поскольку $A$ — квадратная матрица) в ступенчатом виде есть нулевая строка: $$A = \begin{pmatrix}1 & 0 & \dots & 0 \\ 0 & 1 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & 0 \end{pmatrix}$$
> Легко показать, что в этом случае обратной действительно не может существовать, поскольку единичная матрица не содержит нулевых строк, которые неизбежно останутся в $A$, на что бы мы её не умножали.

---
# Определитель

> [!Info]
> **Определителем** $\det A$ квадратной матрицы $A$  $n$-го порядка называется следующее значение: $$\det A = |A| = \Delta = \sum\limits_{\sigma \in S_n} \text{sgn}(\sigma) a_{1\sigma(1)}a_{2\sigma(2)}\dots a_{n\sigma(n)} $$
## Свойства определителя

### Определитель как функция

> **Кососимметричность**
> 
> Если в матрице $A$ $i$-ю и $j$-ю строки такие, что $i < j$, поменять местами, то определитель изменит свой знак:
> $$\det\begin{pmatrix}A_1\\\vdots\\A_j\\\vdots\\A_i\\\vdots\\A_n\end{pmatrix} = -\det \begin{pmatrix}A_1\\\vdots\\A_i\\\vdots\\A_j\\\vdots\\A_n\end{pmatrix}$$
> 
> **Доказательство**
> 
> Пусть $A'$ — матрица, полученная из $A$ путем перемены $i$-й и $j$-й строк местами. 
> По определению, $$\det A' = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma)a_{1\sigma(1)}\dots a_{j\sigma(i)}\dots a_{i\sigma(j)}\dots a_{n\sigma(n)}$$
> Заметим, что операция умножения на транспозицию биективна, то есть каждой перестановке $\sigma$ сопоставлется ровно одна перестановка $\sigma \circ (i, j)$, и наоборот — это выполняется в силу того, что если дважды поменять два элемента местами, то они вернутся на исходную позицию. 
> Если $\sigma$ единоразово принимает значение каждой перестановки из $S_n$, то это же будет верно и для $\sigma \circ (i, j)$, а значит, что мы можем вычислять сумму по транспонированной перестановке: $$\begin{gathered} \det A' = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma \circ (i, j))a_{1\sigma(i)}\dots a_{i\sigma(i)}\dots a_{j\sigma(j)} \dots a_{n\sigma(n)} = \\ \\ = \sum\limits_{\sigma \in S_n}-\text{sgn}(\sigma)a_{1\sigma(i)}\dots a_{i\sigma(i)}\dots a_{j\sigma(j)} \dots a_{n\sigma(n)} = -\det A, \end{gathered}$$
> что и требовалось доказать.

> **Полилинейность**
> 
> Если произвольная строка $A_i$ матрицы $A$ представляется в виде суммы $\alpha A'_i + \beta A''_i$, то верно, что $\det A = \alpha\det A' + \beta\det A''$, где $A'$ и $A''$ — матрицы, в которых $A_i$ заменена на $A'_i$ и $A''_i$ соответственно: $$\det\begin{pmatrix} A_1 \\ \vdots \\ \alpha A'_i + \beta A''_i \\ \vdots \\ A_n \end{pmatrix} = \alpha \det \begin{pmatrix} A_1 \\ \vdots \\ A'_i \\ \vdots \\ A_n \end{pmatrix} + \beta\det \begin{pmatrix} A_1 \\ \vdots \\ A''_i \\ \vdots \\ A_n \end{pmatrix}  $$
> 
> **Доказательство**
> 
> По определению, $$\begin{gathered} \det A = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma)a_{1\sigma(1)}a_{2\sigma(2)}\dots(\alpha a'_{i\sigma(i)} + \beta a''_{i\sigma(i)}) \dots a_{n \sigma(n)} = \\ \\ = \sum\limits_{\sigma \in S_n} \text{sgn}(\sigma) \alpha(a_{1\sigma(1)} a_{2\sigma(2)}\dots a'_{i\sigma(i)} \dots a_{n\sigma(n)}) + \text{sgn}(\sigma)\beta(a_{1\sigma(1)} a_{2\sigma(2)}\dots a''_{i\sigma(i)} \dots a_{n\sigma(n)}) = \\ \\ = \alpha\sum\limits_{\sigma \in S_n} \text{sgn}(\sigma)a_{1\sigma(1)} a_{2\sigma(2)}\dots a'_{i\sigma(i)} \dots a_{n\sigma(n)} + \beta\sum\limits_{\sigma \in S_n} \text{sgn}(\sigma) a_{1\sigma(1)} a_{2\sigma(2)}\dots a''_{i\sigma(i)} \dots a_{n\sigma(n)} = \\ \\ = \alpha \det A' + \beta \det A'',\end{gathered}$$
> что и требовалось доказать.

### Элементарные преобразования

> **Первый тип**
> 
> Если к элементам одной строки добавить соответствующие элементы другой строки, умноженные на какое-то число, то определитель не изменится: $$\det \begin{pmatrix} A_1 \\ \vdots \\ A_i + \lambda A_j \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} = \det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_j \\ \vdots \\ A_n \end{pmatrix}$$
> 
> **Доказательство**
> 
> Из свойства полилинейности следует, что $$\det \begin{pmatrix} A_1 \\ \vdots \\ A_i + \lambda A_j \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} = \det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} + \lambda \det \begin{pmatrix} A_1 \\ \vdots \\ A_j \\ \vdots \\  A_j \\ \vdots \\ A_n\end{pmatrix} $$
> Далее из свойства кососимметричности следует, что $$\det \begin{pmatrix} A_1 \\ \vdots \\ A_j \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} = - \det \begin{pmatrix} A_1 \\ \vdots \\ A_j \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} = 0,$$
> откуда $$\det \begin{pmatrix} A_1 \\ \vdots \\ A_i + \lambda A_j \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} = \det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix} + \lambda \cdot 0 = \det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_j \\ \vdots \\ A_n\end{pmatrix},$$
> что и требовалось доказать.

> **Третий тип**
> 
> Если все элементы произвольной строки умножить на фиксированное число $\lambda$, то определитель увеличится в $\lambda$ раз: $$\det \begin{pmatrix} A_1 \\ \vdots \\ \lambda A_i \\ \vdots \\ A_n \end{pmatrix} = \lambda\det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix} $$
> **Доказательство**
> 
> Из свойства полилинейности следует, что $$\det \begin{pmatrix} A_1 \\ \vdots \\ \lambda A_i \\ \vdots \\ A_n \end{pmatrix} = \det \begin{pmatrix} A_1 \\ \vdots \\ A_i + (\lambda - 1)A_i \\ \vdots \\ A_n \end{pmatrix} = \det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix} + (\lambda - 1)\det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix} = \lambda \det \begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix},$$
> что и требовалось доказать.
> 
> *Следствие 1*. Если матрица содержит нулевую строку, то её определитель равен нулю. Это частный случай теоремы при $\lambda = 0$.
> 
> *Следствие 2*. При умножении матрицы $n$-го порядка на скаляр её определитель увеличивается в $\lambda^n$ раз.

### Частные случаи

> **Пропорциональные ряды**
> 
> Если определитель содержит две пропорциональных строки, то он равен нулю: $$\det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ \lambda A_i \\ \vdots \\ A_n \end{pmatrix} = 0$$
> 
> **Доказательство**
> 
> Из свойства полилинейности следует, что $$\det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ \lambda A_i \\ \vdots \\ A_n \end{pmatrix} = \det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_i + (\lambda - 1)A_i \\ \vdots \\ A_n \end{pmatrix} = \det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix} + (\lambda - 1) \det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix}$$
> Как уже было доказано ранее,  $$\det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ A_i \\ \vdots \\ A_n \end{pmatrix} = 0, $$
> а значит, что $$\det\begin{pmatrix} A_1 \\ \vdots \\ A_i \\ \vdots \\ \lambda A_i \\ \vdots \\ A_n \end{pmatrix} = 0,$$
> что и требовалось доказать.

> **Определитель верхнетреугольной матрицы**
> 
> Определитель верхнетреугольной матрицы равен произведению элементов главной диагонали: $$\det\begin{pmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ 0 & a_{22} & \dots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & a_{nn}\end{pmatrix} = \prod\limits_{i = 1}^na_{ii}$$
> 
> **Доказательство**
> 
> Рассмотрим произвольную верхнетреугольную матрицу $A_n = (a_{ij})$.
> По определению, $$\det A = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma) a_{1\sigma(1)}a_{2\sigma(2)}\dots a_{n\sigma(n)} $$
> Пусть $1 \leq \sigma(1), 2 \leq \sigma(2), \dots, n \leq \sigma(n)$. В таком случае верно, что $1 + 2 +\dots+n \leq \sigma(1) + \sigma(2) + \dots + \sigma(n)$. 
> Совершенно нетрудно заметить, что по определению перестановки это неравенство является тождеством, однако в таком случае тождествами являются и все исходные неравенства, отсюда $\sigma$ — тождественная перестановка.
> 
> Теперь пусть $\exists i: i > \sigma(i)$. В таком случае, по определению верхнетреугольной матрицы, $a_{i\sigma(i)} = 0$, а значит, что любое слагаемое, в котором присутствует этот элемент, обратится в 0 и не будет учтено в итоговой сумме.> Определитель произведения на константу (как следствие из треуг. матрицы)
> 
> Таким образом, единственное потенциально ненулевое слагаемое в определителе — это $a_{11}a_{22}a_{33}\dots a_{nn}$. Легко увидеть, что тогда оно и будет значением определителя, что и требовалось доказать.
> 
> *Следствие 1*. В силу теоремы (4) определитель нижнетреугольной матрицы также равен произведению элементов главной диагонали.
> 
> *Следствие 2*. Определитель единичной матрицы равен 1.

> **Определитель правотреугольной матрицы**
> 
> Определитель правотреугольной матрицы равен произведению всех элементов побочной диагонали, умноженному на $(-1)^{\frac{n(n - 1)}{2}}$: $$\det \begin{pmatrix} 0 & \dots & 0 & a_{1n} \\ 0 & \dots & a_{2n-1} & a_{2n} \\ \vdots & ⋰ & \vdots & \vdots \\  a_{n1} & \dots & a_{nn-1} & a_{nn}\end{pmatrix} = (-1)^\frac{n(n-1)}{2}\prod\limits_{i = 1}^na_{i~n-i+1}$$
> 
> **Доказательство**
> 
> Рассмотрим произвольную правотреугольную матрицу $A_n = (a_{ij})$.
> По определению, $$\det A = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma) a_{1\sigma(1)}a_{2\sigma(2)}\dots a_{n\sigma(n)} $$Аналогичными доказательству теоремы (7) рассуждениями приходим к тому, что в случае, если $\sigma(1) \geq n, \sigma(2) \geq n - 1, \dots, \sigma(n) \geq 1$, перестановка $\sigma$ сопоставляет числу $i$ число $n - i - 1$, а в любом другом случае соответствующее ей слагаемое обращается в ноль. Тогда определитель матрицы $A$ будет равен произведению соответствующих элементов с учётом знака перестановки $\sigma$; нетрудно заметить, что количество инверсий в ней будет равно $(n - 1) + (n - 2) + \dots + 1 = \frac{n(n - 1)}{2}$.

> **Определитель с углом нулей**
> 
> Если матрица $A$ имеет вид $$\begin{pmatrix} B & D \\ 0 & C \end{pmatrix},$$
> где $B, D, 0, C$ — подматрицы, причём $B$ и $C$ — квадратные, а $0$ полностью состоит из нулей, то верно, что $$\det A = \det B \times \det C $$
> **Доказательство**
> 
> Пусть подматрица $B$ имеет размер $m \times m$, $C$ — $k \times k$.
> Вспомним определение определителя: $$\det A = \sum\limits_{\sigma \in S_n} \text{sgn}(\sigma) a_{1\sigma(1)}a_{2\sigma(2)}\dots a_{n\sigma(n)}$$
> Рассмотрим первые $m$ строк матрицы. Если нашлась строка $i$ такая, что $\sigma(i) > m$, то далее будет обязана найтись строка $j > m$ такая, что $\sigma(j) < m$ и, поскольку тогда $a_{j\sigma(j)} = 0$, соответствующее слагаемое также будет равняться $0$.
> 
> Таким образом, в определителе будут учтены лишь слагаемые, все элементы которых принадлежат только подматрицам $B$ и $C$. Эти слагаемые соответствуют перестановкам $\sigma = \sigma_1 \circ (m + \sigma_2)$, где $\sigma_1 \in S_m, \sigma_2 \in S_k, (m + \sigma_2)(i) = m + \sigma_2(i)$. Формально, $$\det A = \left(\sum\limits_{\sigma_1 \in S_m}\text{sgn}(\sigma_1) \prod\limits_{i = 1}^m a_{i\sigma_1(i)}\right) \times \left(\sum\limits_{\sigma_2 \in S_k} \text{sgn}(\sigma_2) \prod \limits_{i = 1}^{k} a_{i+m~ \sigma_2(i) + m} \right), $$
> что в точности равняется $\det B \times \det C$, что и требовалось доказать. 
> 
> *Примечание*. В силу того, что транспонирвоание не изменяет определитель, теорема также верна, если угол нулей будет находиться справа сверху.

### Общие свойства

> **Транспонирование**
> 
> Транспонирование матрицы не изменяет её определитель.
> 
> **Доказательство**
> 
> По определению, $$\det A = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma)a_{1\sigma(1)}a_{2\sigma(2)}\dots a_{n\sigma(n)}, $$
> тогда $$\begin{gathered} \det A^T = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma)a_{\sigma(1)1}a_{\sigma(2)2}\dots a_{\sigma(n)n} \end{gathered}$$
> Воспользовавшись тем, что $\sigma^{-1}(\sigma(i)) = i$, мы можем записать пары индексов $(\sigma(i), i)$ как $(\sigma(i), \sigma^{-1}(\sigma(i))$. Перегруппировав множители таким образом, чтобы все $\sigma(i)$ шли в порядке возрастания, получим, что $$\begin{gathered} \det A^T = \sum\limits_{\sigma \in S_n}\text{sgn}(\sigma)a_{1\sigma^{-1}(1))}a_{2\sigma^{-1}(2)}\dots a_{n\sigma^{-1}(n)} \end{gathered} $$
> Теперь вспомним, что каждой перестановке $\sigma$ соответствует ровно одна перестановка $\sigma^{-1}$, и наоборот. Если $\sigma$ единоразово принимает значение каждой перестановки из $S_n$, то это же будет верно и для $\sigma^{-1}$, а значит, что мы можем вычислять сумму по $\tau = \sigma^{-1}$: $$\begin{gathered} \det A^T = \sum\limits_{\tau \in S_n}\text{sgn}(\tau)a_{1\tau(1)}a_{2\tau(2)}\dots a_{n\tau(n)} \end{gathered} $$
> Заметим, что поскольку $\text{sgn}(\sigma) = \text{sgn}(\sigma^{-1})$, то это значение в точности равно $\det A$, что и требовалось доказать.
> 
> *Следствие*. Все свойства, применимые к строкам, применимы к столбцам, и наоборот.

> **Теорема 4**
> 
> Следующие условия эквивалентны:
> 1. $\det A \neq 0$;
> 2. строки $A$ линейно независимы;
> 3. столбцы $A$ линейно независимы;
> 4. $A$ невырождена;
> 5. существует матрица, обратная к $A$.
> 
> **Доказательство**
> 
> Условия 2, 3 и 4 эквивалентны по определению ранга. Эквивалентность условий 4 и 5 следует из алгоритма нахождения обратной матрицы.
> 
> Докажем, что условие 1 эквивалентно условию 4.
> 
> Приведём $A$ к ступенчатому виду $A'$ элементарными преобразованиями строк — в таком случае $\det A' \neq 0 \iff \det A \neq 0$.
> Заметим, что $A'$ — верхнетреугольная матрица, а значит, что её определитель равен произведению диагональных элементов. Это произведение не равно нулю лишь в том случае, когда каждый из диагональных элементов отличен от нуля или, иными словами, когда матрица строго ступенчата, что и означает её невырожденность.

> **Лемма 14**
> 
> Для любой матрицы $A$ и элементарной матрицы $E$ верно, что $$\det(E\times A) = \det E \times \det A$$
> **Доказательство**
> 
> Определитель элементарной матрицы первого типа равен $1$. Было показано, что первое элементарное преобразование не изменяет определитель.
> 
> Определитель элементарной матрицы первого типа равен $-1$, поскольку единственная ненулевая перестановка будет содержать ровно одну инверсию. Согласно свойству кососимметричности, второе элементарное преобразование изменяет только знак определителя.
> 
> Определитель элементарной матрицы третьего типа равен $\lambda$. Было показано, что третье элементарное преобразование увеличивает определитель в $\lambda$ раз.

> **Теорема 3**
> 
> Определитель произведения равен произведению определителей: $$\det(AB) = \det A \times \det B $$
> **Доказательство**
> 
> Если матрица $A$ вырождена, то вырождена и матрица $AB$, так как если бы существовала матрица, обратная к произведению, то, согласно лемме (13), существовала бы и матрица, обратная к $A$, что привело бы к противоречию.
> 
> Если матрица $A$ невырождена, то она представима в виде произведения элементарных матриц: $$A = E_1E_2 \dots E_k, $$
> откуда, по лемме 14, $$\det(AB) = \det(E_1E_2\dots E_kB) = \det (E_1E_2\dots E_k) \times \det B = \det A \times \det B,$$что и требовалось доказать.

# Минор матрицы

> [!Info]
> **Минором** $M_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}$ порядка $k$ матрицы $A = (a_{ij})_{m \times n}$ называется определитель матрицы $A'$ такой, что 
> $$
> A' = 
> \begin{vmatrix} 
> a_{i_1j_1} & a_{i_1j_2} & \dots & a_{i_1j_k} \\ 
> a_{i_2j_1} & a_{i_2j_2} & \dots & a_{i_2j_k} \\ 
> \vdots & \vdots & \ddots & \vdots \\
> a_{i_kj_1} & a_{i_kj_2} & a_{i_kj_k}
> \end{vmatrix} 
> $$
> Иными словами, минор — это определитель подматрицы, состоящей только из элементов на пересечении строк с индексами $i_1, i_2, \dots, i_k$ и столбцов с индексами $j_1, j_2, \dots, j_k$.
> 
> Минор $M_{\begin{pmatrix} i \\ j \end{pmatrix}}$, определённый на подматрице, состоящей из одной строки и одного столбца, будем записывать $M_{ij}$ по их номерам.
> 
> *Замечание*. Если $k > n$ или $k > m$, то $M_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}} = 0$

> [!Info]
> **Дополнительным минором** $\overline{M}_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}$ произвольного минора $M_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}$ некоторой квадратной матрицы $A = (a_{ij})_{m \times n}$ называется определитель матрицы, получаемой из исходной путём вычеркивания строк с индексами $i_1, i_2, \dots, i_k$ и столбцов с индексами $j_1, j_2, \dots, j_k$.

> [!Info]
> **Алгебраическим дополнением** $A_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}$ минора $M_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}$ порядка $k$ называется число, равное $$(-1)^{\sum\limits_{p = 1}^ki_p + j_p} \times  \overline{M}_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}$$
> В частности, алгебраическое дополнение элемента $a_{ij}$ матрицы $A$ представляет собой произведение дополнительного минора $\overline{M_{ij}}$ на $(-1)^{i + j}$.

> **Лемма 15**
> 
> Сумма попарных произведений элементов какой-либо строки матрицы на соответствующие алгебраические дополнения элементов другой строки равна нулю.
> 
> **Доказательство**
> 
> Рассмотрим строки $p$ и $q$ матрицы $A$
> Построим вспомогательную матрицу $B$, заменив $q$-ю строку на $p$-ю: $$B = \begin{pmatrix}a_{11} & \dots  &a_{1n} \\ \vdots & \ddots & \vdots \\ a_{p1} & \dots & a_{pn} \\ \vdots & \ddots & \vdots \\ a_{p1} & \dots & a_{pn} \\ \vdots & \ddots & \vdots \\ a_{m1} & \dots & a_{mn} \end{pmatrix}$$
> По **теореме 7**, $\det B = 0$. Его разложение по $q$-й строке имеет следующий вид: $$\det B = \sum\limits_{j = 1}^n b_{qj}B_{qj} $$
> По построению, $b_{qj} = a_{pj}$ и $B_{qj} = A_{qj}$. Имеем: $$\det B = \sum\limits_{j = 1}^na_{pj}A_{qj} = 0, $$
> что и требовалось доказать.

# Вычисление определителя

> **Теорема Лапласа**
> 
> Определитель квадратной матрицы $A_n$ равен сумме всевозможных миноров $k$-го порядка, выбранных в зафиксированных $k$ строках (столбцах), на их алгебраические дополнения: $$ \det A = \sum\limits_{1 \leq j_1 < j_2 < \dots < j_k \leq n}M_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}A_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}} $$
> или $$ \det A = \sum\limits_{1 \leq i_1 < i_2 < \dots < i_k \leq n}M_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}}A_{\begin{pmatrix}i_1 & i_2 & \dots & i_k \\ j_1 & j_2 & \dots & j_k \end{pmatrix}} $$
> 
> 
> **Доказательство** не уверен, что вообще нужно, но если понадобится, то оно тут появится

> **Лемма 16**
> 
> Если матрица $A$ имеет вид $$\begin{pmatrix}a_{11} & a_{12} & a_{13} & \dots & a_{1n} \\ a_{21} & a_{22} & a_{23} & \dots & a_{2n} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & a_{ij} & \dots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & a_{m3} & \dots & a_{mn} \end{pmatrix}$$
> или, иными словами, содержит строку, состоящую из нулей за исключением элемента $a_{ij}$, то верно, что $$\det A =a_{ij}A_{ij} $$
> **Доказательство**
> 
> Будем менять $i$-ю строку с предыдущими до тех пор, пока она не займёт первую позицию. Аналогично поступим с $j$-м столбцом. В результате определитель изменит свой знак $i - 1 + j - 1$ раз, что аналогично умножению его на $(-1)^{i+j}$. 
> Получившаяся матрица имеет следующий вид: $$\begin{pmatrix}a_{ij} & 0 & 0 &\dots & 0 \\ a_{1j} & a_{11} & a_{12} & \dots & a_{1n} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ a_{mj} & a_{m1} & a_{m2} & \dots & a_{mn} \end{pmatrix}$$
> Применим теорему об определителе с углом нулей и получим, что определитель этой матрицы равен произведению элемента $a_{ij}$ на определитель матрицы, получаемой из исходной путём исключения $i$-й строки и $j$-го столбца, то есть на дополнительный минор этого элемента. Учитывая множитель $(-1)^{ij}$, имеем $$\det A = a_{ij} \overline{M}_{ij}(-1)^{i + j} = a_{ij}A_{ij},$$
> что и требовалось доказать.

> **Разложение определителя** 
> 
> Для произвольной строки $i$ квадратной матрицы $A$ верно, что $$\det A = \sum\limits_{j = 1}^n a_{ij}A_{ij} $$
> Аналогично, для столбца $j$: $$\det A = \sum\limits_{i = 1}^na_{ij}A_{ij}$$
> 
> **Доказательство**
> 
> Докажем разложение определителя по строке. Рассуждения для разложения по столбцу аналогичны.
> 
> Пусть $i$-я строка имеет вид $(a_{i1}, a_{i2}, \dots, a_{in})$. Разложим её в сумму $n$ строк: $$(a_{i1}, a_{i_2}, \dots, a_{in}) = (a_{i_1}, 0, \dots, 0) + (0, a_{i_2}, \dots, 0) + \dots + (0, 0, \dots, a_{in}) $$
> Обозначим $A_j$ матрицу, в которых мы заменили $i$-ю строку на $j$-е из приведенных выше слагаемых. Тогда, согласно свойству полилинейности и *лемме*, имеем $$\det A = \sum\limits_{j = 1}^n \det A_k = \sum_{j = 1}^n a_{ij}A_{ij},$$
> что и требовалось доказать.

---
