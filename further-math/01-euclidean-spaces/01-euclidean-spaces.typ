#import "../../typst-lib/main.typ": *

#set text(size: 14pt)

#notes-header([Евклидовы пространства])

#notes-sub([Некоторые хорошие типы пространств])

#def(
  [Метрическое пространство],
  [
    множество $M$, на котором задана функция-метрика
    $
      rho : M^2 -> RR
    $
    обладающая следующими свойствами:
    - Симметричность: $rho(x, y) = rho(y, x)$
    - Положительноопределенность: $rho(x, y) >= 0, rho(x, y) = 0 <==> x = y$
    - Неравенство треугольника: $rho(x, z) <= rho(x, y) + rho(y, z)$

    *Примеры:*
    - $x, y in RR$, тогда $rho(x, y)=abs(x-y)$
    - $x, y in RR^n$, тогда $dots$
  ],
)

#def(
  [Нормированное пространство],
  [
    линейное пространство $V$, в котором задано отображение --- норма
    $
      norm(x) : V -> RR
    $
    обладающая следующими свойствами:
    - Мультипликативность: $norm(lambda x) = abs(lambda) dot norm(x)$
    - Положительноопределенность: $norm(x) >= 0, norm(x) = 0 <==> x = 0$
    - Неравенство треугольника: $norm(x + y) <= norm(x) + norm(y)$

    *Пример:*\
    $norm(x)_p = root(p, limits(sum)_(i=1)^n x_i^p)$, где
  ],
)

#notes-sub([Скалярное произведение. Евклидово пространство], pgbreak: true)

#def(
  [Скалярное произведение],
  [
    функция $(x, y) : V^2 -> RR$, обладающая следующими свойствами:
    - Билинейность:
      - $(x + z, y) = (x, y) + (z, y)$ --- аддитивность
      - $(lambda x, y) = (x, lambda y) = lambda dot (x, y)$ --- мультипликативность
    - Симметричность: $(x, y) = (y, x)$
    - Положительноопределенность:\ $(x, x) >= 0$, причем $(x, x) = 0 <==> x = 0$
  ],
)

#def(
  [Евклидово пространство],
  [
    линейное пространство $E$, на котором определено скалярное произведение
  ],
)
Размерность Евклидова пространства равна размерности пространства, которое его "порождает" $dim E = dim V$

#theorem(
  name: [Неравенство Коши-Буняковского],
  [
    $
      (forall x, y in E)(abs((x, y)) <= sqrt((x, x)) dot sqrt((y, y)))
    $
    причем равенство достигается $<==> x = lambda y$

    *P.S.* В Евклидовом пространстве можно записать как $ abs((x, y)) <= norm(x) dot norm(y) $
  ],
  [
    Рассмотрим 2 случая:
    + $y = 0$:\
      $(x, compl(0)) = (x, 0 dot compl(0)) = 0 dot (x, compl(0)) = 0$
    + $y != 0$:\
      Пусть $f(t) = (x + t y, x + t y), t in RR$, тогда
      #block(
        width: 100%,
        $
          & f(t) = (x, x) + t dot (x, y) + t dot (y, x) + (y, y) dot t^2 \
          & f(t) = (y, y) dot t^2 + 2 (x, y) dot t + (x, x)
        $,
      )

      По определению $f(t) = (a, a) ==> f(t) >= 0 ==> D >= 0 <==> D/4 >= 0$

      Посчитаем дискриминант этого выражения
      $
        & D/4 = (x, y)^2 - (x, x) dot (y, y) <= 0 \
        & (x, y)^2 <= (x, x) dot (y, y) \
        & (x, y) <= sqrt((x, x)) dot sqrt((y, y))
      $
  ],
)

В Евклидовом пространстве нормой является квадратный корень из скалярного произведения вектора на него же:
$
  (forall x in E)(norm(x) = sqrt((x, x)))
$
Докажем свойства функции-нормы
#theor-proof(
  [
    - $norm(x) >= 0$ по определению корня
    - $norm(lambda x) = sqrt((lambda x, lambda x)) = sqrt(lambda^2 (x, x)) = abs(lambda) dot sqrt((x, x)) = abs(lambda) dot norm(x)$
    - $norm(x + y) <= norm(x) + norm(y)$. Возведем левую часть во 2 степень:
      #block(
        width: 100%,
        $
          norm(x + y)^2 = norm(x)^2 + underbracket(2 dot (x, y), <= 2 dot norm(x) dot norm(y)) + norm(y)^2 <= (norm(x) + norm(y))^2
        $,
      )
  ],
)

Типы норм:
+ $norm(x)_2$ --- стандартная (евклидова, шаровая, сферическая)
+ $norm(x)_1 = limits(sum)_(i = 1)^n x_i$ --- манхэттенская  (октоэдрическая)
+ $norm(x)_oo = max{x_i | 1 <= i <= n}$ --- кубическая (норма-бесконечность)
+ В $C_([a, b])$ тоже есть, как-то через интегралы
+ Норма матрицы --- такая же характеристика для матрицы. Для матрицы норму определить следующим образом:
  - Столбцовая #block(width: 100%, $ norm(A)_1 = limits(max)_(j=1)^m limits(sum)_(i = 1)^n abs(a_(i j)) $)
  - Строчная $ norm(A)_oo = limits(max)_(i=1)^n limits(sum)_(j = 1)^m abs(a_(i j)) $
  - Спектральная (кв. матрица) $ norm(A)_2 = sqrt(lambda_max (A^T dot A)) $ где $lambda_max$ --- максимальное собственное значение матрицы $(A^T dot A)$
  #fun-fact-headered(
    [Что такое собственное число],
    [
      Как известно, матрицы являются формой записи линейных операторов. Собственным числом матрицы называется произвольное число $lambda$, при котором уравнение
      $
        A x = lambda x
      $
      имеет ненулевое решение $x$. То есть, применяя оператор к вектору $x$ мы получим вектор $x' = lambda x$, который будет коллинеарен исходному
    ],
  )
  - Норма Фробениуса --- квадратный корень из суммы квадратов всех элементов матрицы $ norm(A)_F = sqrt(limits(sum)_(i=1)^n limits(sum)_(j=1)^m (a_(i j))^2) $

#notes-sub([Немного об углах между векторами], pgbreak: true)

Вернемся к неавенству Коши-Буняковского:
$
  norm((x, y)) <= norm(x) dot norm(y)
$
поделим на левую часть (случай где хоть 1 из векторов нулевой рассматривать не будем):
$
  norm((x,y))/(norm(x) dot norm(y)) <= 1
$
Скажем, что
$
  cos phi = norm((x,y))/(norm(x) dot norm(y))
$
где $phi$ --- угол между векторами $x$ и $y$, то есть углом между векторами $x$ и $y$ будем называть величину
$
  phi = arccos norm((x,y))/(norm(x) dot norm(y))
$


#notes-sub([Ортонормированная система векторов. Матрица Грама], pgbreak: true)
#def(
  [Ортогональные векторы],
  [
    векторы, угол между которыми равен $90degree$ (или скалярное произведение которых равно $0$)
  ],
)
#def(
  [Ортонормированная система векторов],
  [
    множество попарно ортогональных векторов $V = {v_1, v_2, dots}$, норма каждого из которых равна 1:
    $
      cases(
        (forall v_i, v_j in V)((v_i, v_j) = 0),
        (forall v in V)(norm(v) = 1)
      )
    $
  ],
)

#theorem(
  [Ортогональная система векторов (не содержащая $altvct(0)$) является ЛНЗ],
  [
    Пусть $a_1, a_2, dots, a_k$ --- ортогональная система векторов. Подберем $lambda_i$, такие что $ y = lambda_1 a_1 + lambda_2 a_2 + dots + lambda_k a_k = altvct(0) $
    Рассмотрим
    $
      & (y, a_i) = (lambda_1 a_1, a_i) + (lambda_2 a_2, a_i) + dots + (lambda_k a_k, a_i) = \
      & = lambda_1(a_1, a_i) + lambda_2 (a_2, a_i) + dots + lambda_k (a_k, a_i) = \
      & = lambda_i (a_i, a_i)
    $
    А поскольку $y =altvct(0)$, получим $(y, a_i) = 0$, откуда
    $
      lambda_i (a_i, a_i) = 0
    $
    а так как $a_i != altvct(0)$ (по условию), $(a_i, a_i) != 0$ (по определению скалярного произведения), а значит $lambda_i = 0$. Это верно $forall i in [1, k]$, а значит система ЛНЗ.
  ],
)

#theorem(
  name: [Теорема Пифагора],
  [
    В любой ортогональной системе векторов $a_1, a_2, dots, a_k$ выполняется равенство
    $
      norm(limits(sum)_(i = 1)^k a_i)^2 = limits(sum)_(i = 1)^k norm(a_i)^2
    $
  ],
  [
    Пусть $a_1, a_2, dots, a_k$ --- ортогональная система векторов, тогда
    $
      & norm(limits(sum)_(i = 1)^k a_i)^2 = (limits(sum)_(i = 1)^k a_i, limits(sum)_(i = 1)^k a_i) = \
      & = (a_1+ a_2+ dots + a_k, a_1+ a_2+ dots + a_k) = \
      & = limits(sum)_(i = 1)^k (a_1, a_i) + limits(sum)_(i = 1)^k (a_2, a_i) + dots + limits(sum)_(i = 1)^k (a_k, a_i) = \
      & = (a_1, a_1) + (a_2, a_2) + dots + (a_k, a_k) = \
      & = norm(a_1)^2 + norm(a_2)^2 + dots + norm(a_k)^2 = limits(sum)_(i = 1)^k norm(a_i)^2
    $
  ],
)

Рассмотрим произвольную ЛНЗ систему векторов $S = (e_1, e_2, dots, e_n)$ в Евклидовом пространстве $E^n$, она ЛНЗ и их $n$ штук, а значит, является базисом, рассмотрим
$
  & x = x_1 e_1 + x_2 e_2 + dots + x_n e_n \
  & y = y_1 e_1 + y_2 e_2 + dots + y_n e_n
$
Рассмотрим скалярное произведение $(x, y)$:
$
  & (x, y) = (x_1 e_1 + x_2 e_2 + dots x_n e_n, y_1 e_1 + y_2 e_2 + dots + y_n e_n) = \
  & limits(sum)_(i = 1)^n limits(sum)_(j = 1)^n x_i y_j (e_i, e_j)
$
Пусть теперь $(e_i, e_j) = G_(i j)$ (очевидно, $G_(i j)$ --- скаляр), тогда
$
  (x, y) = limits(sum)_(i = 1)^n limits(sum)_(j = 1)^n x_i y_j G_(i j)
$

#def(
  [Матрица Грама],
  [
    для системы векторов $S = (e_1, e_2, dots, e_n)$ матрицей Грама называется квадратная матрица $G_S$ размера $n times n$, где $G_(i j) = (e_i, e_j)$:
    $
      G_S = mat(
        (e_1, e_1), (e_1, e_2), dots.c, (e_1, e_n);
        (e_2, e_1), (e_2, e_2), dots.c, (e_2, e_n);
        dots.c;
        (e_n, e_1), (e_n, e_2), dots.c, (e_n, e_n)
      )
    $
    Свойства матрицы Грама:
    - $G_S = G_S^T$ (симметричность)
    - Положительноопределенность всех главных угловых миноров:
      $
        & (e_1, e_1) >= 0 \
        & mat(
            delim: "|",
            (e_1, e_1), (e_1, e_2);
            (e_2, e_1), (e_2, e_2)
          ) >= 0 \
        & dots
      $
    - Если $S$ --- ЛНЗ, то $det G_S != 0$
    - Если $S$ --- ортогональна, то $G_S$ --- диагональная
    - Если $S$ --- ортонормирована, то $G_S$ --- единичная
  ],
)

#theorem(
  [
    Пусть $S = (e_1, e_2, dots, e_n)$ --- базиз $E^n$ и $X = (x_1, x_2, dots, x_n)^T, Y$ --- координаты векторов $x, y$ в базисе $S$, тогда
    $
      (x, y) = (x_1, x_2, dots, x_n) dot G_S dot vec(y_1, y_2, dots.c, y_n) = X^T dot G_S dot Y
    $
  ],
  [
    Для доказательства просто покажем, что такое произведение дает сумму из предыдущего рассуждения:
    $
      X^T dot G_S = (limits(sum)_(i = 1)^n (x_i dot (e_i, e_1)), dots, limits(sum)_(i = 1)^n (x_i dot (e_i, e_n)))
    $
    теперь домножим на $Y$:
    $
      & limits(sum)_(i = 1)^n (x_i dot (e_i, e_1)) dot y_1 + dots + limits(sum)_(i = 1)^n (x_i dot (e_i, e_n)) dot y_n = \
      & = limits(sum)_(i = 1)^n limits(sum)_(j = 1)^n x_i y_j (e_i, e_j)
    $
  ],
)


#notes-sub([Ортогонализация], pgbreak: true)
#theorem(
  [Любую ЛНЗ систему можно ортогонализировать],
  [
    Следующий процесс называется *ортогонализацией Грама-Шмидта*. Его суть заключается в итератианом разложении каждого $a_k$ на 2 составляющие: $e_k$ --- новый вектор, ортогональный всем предыдущим, $g_k$ --- составляющая $a_k$, лежащая в линейной оболочке, порождаемой предыдущими векторами, поэтому положим
    $
      g_k := limits(sum)_(i=1)^(k-1)(lambda_i a_i)
    $
    то есть
    $
      a_k = e_k + g_k = e_k + limits(sum)_(i=1)^(k-1)(lambda_i a_i)
    $
    откуда
    $
      e_k = a_k - g_k = a_k - limits(sum)_(i=1)^(k-1)(lambda_i a_i)
    $
    далее $lambda$ заменим на $alpha$ с другими индексами и для удобства поменяем знак.

    Доказательство корректности такого выражения $a_k$ оставим на потом.

    Пусть $S = (a_1, a_2, dots, a_n)$ ЛНЗ, тогда построим ортогональную систему $S_perp = (e_1, e_2,dots, e_n)$:
    + $e_1 = a_1$
    + Подбираем $alpha_2$, такое что $e_2 = a_2 + alpha_2 e_1$ и $(e_1, e_2) = 0$, распишем:
      $
        & (e_1, e_2) = (e_1, a_2 + alpha_2 e_1) = (e_1, a_2) + (e_1, alpha_2 e_1) = \
        & (e_1, a_2) + alpha_2 (e_1, e_1) = 0
      $
      откуда
      $
        alpha_2 = -((e_1, a_2)) / ((e_1, e_1)) = - ((e_1, a_2)) / norm(e_1)^2
      $
    + Подбираем $alpha_(32)$ и $alpha_31$, чтобы $e_3 = a_3 + alpha_32 e_2 + alpha_31 e_1$ и $(e_1, e_3) = 0$ и $(e_2, e_3) = 0$, снова выразим $alpha_31$:
    $
      & (e_1, e_3) = (e_1, a_3 + alpha_31 e_1 + alpha_32 e_2) = \
      & = (e_1, a_3) + alpha_31(e_1, e_1) + alpha_32(e_1, e_2) = \
      & = (e_1, a_3) + alpha_31 dot norm(e_1)^2 + 0 = 0 ==> \
      & ==> alpha_31 = - ((e_1, a_3))/norm(e_1)^2
    $
    И аналогично $alpha_32$:
    $
      alpha_32 = - ((e_2, a_3))/norm(e_2)^2
    $
    Обобщим построение вектора $e_k$:

    $
      & e_k = a_k + alpha_(k 1) e_1 + alpha_(k 2)e_2 + dots + alpha_(k [k-1])e_(k-1) = \
      & = a_k + limits(sum)_(i = 1)^(k-1) (alpha_(k i) e_i)
    $
    выразим $alpha_(k i)$ из утверждения $(e_i, e_k) = 0$:
    $
      & (e_i, e_k) = (e_i, a_k + alpha_(k 1) e_1 + alpha_(k 2)e_2 + dots + alpha_(k [k-1])e_(k-1)) = \
      & = (e_i, a_k) + alpha_(k 1)(e_i, e_1) + alpha_(k 2)(e_i, e_2) + dots + alpha_(k [k-1])(e_i, e_(k-1))
    $
    вспомним, что $i != j ==> (e_i, e_j) = 0$ (здесь $i, j < k$, то есть векторы ортогональны), тогда останется
    $
      (e_i, e_k) = (e_i, a_k) + alpha_(k i)(e_i, e_i) = (e_i, a_k) + alpha_(k i) dot norm(e_i)^2 = 0
    $
    откуда получим
    $
      alpha_(k i) = - ((e_i, a_k))/norm(e_i)^2
    $
    подставляя коэффициенты в формулу получаем
    $
      e_k = a_k - limits(sum)_(i=1)^k (((e_i, a_k))/norm(e_i)^2 dot e_i)
    $
    Таким образом, получается система ЛНЗ векторов $S_perp = {e_1, e_2, dots, e_n}$, в которой все векторы попарно ортогональны, что соответствует определению ортогональности системы $S_perp$.
  ],
)

Для получения из ортогональной системы $S_perp$ ортонормированной системы $cal(S)$ каждый вектор нужно нормировать:
$
  q_i = e_i/norm(e_i)
$
то есть
$
  cal(S) = {e_i/norm(e_i) : e_i in S_perp}
$

// Забавный факт (мы зачем-то хотим это знать) $norm(e_k) <= norm(a_k)$, докажем это

#theorem(
  [Нам почему-то (товарищи ревьюеры, ваш выход) интересно знать, что $ norm(e_k) <= norm(a_k) $],
  [
    $
      & norm(e_k)^2 = (e_k, e_k) = (e_k, a_k - limits(sum)_(i=1)^(k-1) (((e_i, a_k))/norm(e_i)^2 dot e_i)) = \
      & = (e_k, a_k) + beta_1(e_k, e_1) + beta_2(e_k, e_2) + dots + beta_(k-1)(e_k, e_(k-1)) = \
      & = (e_k, a_k) <= norm(e_k) dot norm(a_k) ==> norm(e_k) <= norm(a_k)
    $
  ],
)

#notes-sub([$Q R$-разложение матриц], pgbreak: true)
Основано на ортогонализации Грама-Шмидта. Пусть дана матрица $A_n$, считая каждый столбец матрицы $A_n$ вектором $a_i$, ортогонализируем систему векторов $S = {a_i : i in [1, n]}$, после чего сразу нормируем векторы, получая (через переходы $a_i -> e_i -> q_i$) ортонормированную систему $cal(S) = {q_i : i in [1, n]}$, построив из $q_i$ как из столбцов матрицу, получим $Q_n$

Положим $A = Q R$ ($A$ дана, $Q$ --- найдена). Из равенства легко видеть, что
$
  R = Q^(-1) A
$

#theorem(
  name: [Как по мне, совсем не очевидный факт],
  [
    Утверждается, что
    $
      Q^T dot Q = I
    $
  ],
  [
    Обозначим элементы:
    $
      Q = mat(
        q_11, q_12, dots.c, q_(1 n);
        q_21, q_22, dots.c, q_(2 n);
        dots.c;
        q_(n 1), q_(n 2), dots.c, q_(n n)
      )
    $
    тогда
    $
      Q^T = mat(
        q_11, q_21, dots.c, q_(n 1);
        q_12, q_22, dots.c, q_(n 2);
        dots.c;
        q_(1 n), q_(2 n), dots.c, q_(n n)
      )
    $
    А также обозначим векторы как столбцы $Q$:
    $
      v_i = (q_(1 i), q_(2 i), dots, q_(n i))^T
    $
    Таким образом получаем
    $
      Q^T dot Q = mat(
        (v_1, v_1), (v_1, v_2), dots.c, (v_1, v_n);
        (v_2, v_1), (v_2, v_2), dots.c, (v_1, v_n);
        dots.c;
        (v_n, v_1), (v_n, v_2), dots.c, (v_n, v_n)
      )
    $
    однако мы знаем, что $i != j ==> (v_i, v_j) = 0$ (система $Q$ ортонормирована), а значит
    $
      Q^T dot Q = mat(
        norm(v_1)^2, 0, dots.c, 0;
        0, norm(v_2)^2, dots.c, 0;
        dots.c;
        0, 0, dots.c, norm(v_n)^2
      )
    $
    а поскольку система нормирована, $norm(v_i) = 1 ==> norm(v_i)^2 = 1$, то есть
    $
      Q^T dot Q = mat(
        1, 0, dots.c, 0;
        0, 1, dots.c, 0;
        dots.c;
        0, 0, dots.c, 1
      ) = I
    $

    К слову, из того, что матрицы квадратные, следует, что $ Q^T dot Q = Q dot Q^T = I ==> Q^T = Q^(-1) $
  ],
)
Пользуясь предыдущим фактом, получаем
$
  R = Q^(-1) dot A = Q^T dot A
$
