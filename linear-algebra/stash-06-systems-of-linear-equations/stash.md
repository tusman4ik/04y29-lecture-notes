##### Содержание
1. Основные определения
2. Классификация СЛАУ
3. Матричное представление СЛАУ
4. Метод Гаусса
5. Вид множества решений СЛАУ
	1. Фундаментальная система решений
	2. Общий вид множества решений СЛАУ
6. Критерии совместности и определённости СЛАУ
7. Метод Крамера

---
$$
\hspace{4cm}
\begin{array}{r}
\textit{"Жизнь вообще несправедлива, а это просто одно из проявлений.”} \\
	\text{— И. В. Аржанцев}
\\[-0.8em]
\rule{7cm}{0.3pt}
\end{array}
$$
# Основные определения

> [!Info]
> **Системой из $m$ линейных алгебраических уравнений** (далее — СЛАУ) с $n$ неизвестными называется система уравнений вида: $$\begin{cases} a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1 \\ a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2 \\ ~~~~~~~~~~~~~~~~~~~~~~~~~\dots \\ a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n = b_m \end{cases} $$
> где:
> - $a_{ij}$ — коэффициент;
> - $x_i$ — неизвестная;
> - $b_i$ — свободный член.

> [!Info]
> Набор чисел $\langle x_1^*, x_2^*, \dots, x_n^* \rangle$ называется **решением** СЛАУ, если при подстановке их в систему каждое из уравнений обращается в тождество.
> 
> **Решить** систему — значит найти все возможные её решения, или доказать, что их не существует.

---

# Классификация СЛАУ

> **Совместные**
> 
> Если СЛАУ имеет хотя бы одно решение, она называется *совместной*. В противном случае такая система называется *несовместной*.

> **Определенные**
> 
> Если СЛАУ имеет ровно одно решение, она называется *определенной*. В случае, если она имеет более одного решения, она называется *неопределенной*.

> **Однородные**
> 
> Если все свободные члены в СЛАУ равны $0$, она называется *однородной*. В противном случае она называется *неоднородной*.

> **Равносильные**
> 
> Если множества решений двух СЛАУ совпадают, то эти системы называются *равносильными*.

---

# Матричное представление СЛАУ

> [!Info]
> СЛАУ из $m$ уравнений с $n$ неизвестными представима в виде матрицы $A_{m\times n}$ следующего вида: $$A = \begin{pmatrix} 
> a_{11} &  a_{12} & \dots & a_{1n} \\ 
> a_{21} & a_{22} & \dots & a_{2n} \\
> \vdots & \vdots & \ddots & \vdots \\
> a_{m1} & a_{m2} & \dots & a_{mn} 
> \end{pmatrix} $$
> Такая матрица называется **матрицей системы** или **матрицей коэффициентов**.

> [!Info]
> Если к матрице коэффициентов дописать столбец свободных членов, получится матрица $A|B$ следующего вида: $$ A|B = 
> \left(
> \begin{array}{cccc|c}
>   a_{11} & a_{12}  &\dots & a_{1n} & b_1 \\
>   a_{21} & a_{22} & \dots & a_{2n} & b_2 \\
>   \vdots & \vdots & \ddots & \vdots & \vdots \\
>   a_{m1} & a_{m2} & \dots & a_{mn} & b_m
> \end{array}
> \right) $$
> Такая матрица называется **расширенной матрицей** системы.

> **Теорема 1**
> 
> СЛАУ, получающиеся друг из друга элементарными преобразованиями соответствующих расширенных матриц, равносильны.
> 
> **Доказательство**
> 
> Нетрудно заметить, что если набор $\langle x_1^*, x_2^*, \dots, x_n^* \rangle$ был решением системы, то после любого из элементарных преобразований он также будет им являться. Проверить этот факт особенно любопытным читателям предлагается самостоятельно.

---

# Метод  Гаусса

Метод Гаусса — один из наиболее простых и широко распространенных способов решения СЛАУ, непосредственно опирающийся на только что приведённую теорему (1).
Рассмотрим принцип его работы на примере произвольной системы из 3 уравнений с 4 неизвестными: $$
\begin{cases} 
4x_1+8x_2+6x_3+4x_4 = 28 \\ 
-8x_1-11x_2-2x_3+2x_4=-26 \\
8x_1+26x_2+32x_3+52x_4=188
\end{cases}$$
Так, метод Гаусса предлагает следующий алгоритм:

> **Шаг 1 (Прямой ход)**
> 
> Приведём расширенную матрицу системы к улучшенному ступенчатому виду:
> 
> $$\left( \begin{array}{cccc|c} 4 & 8 & 6 & 4 & 28 \\ -8 & -11 & -2 & 2 & -26 \\ 8 & 26 & 32 & 52 & 188 \end{array} \right)$$
> $$\left( \begin{array}{cccc|c} 4 & 8 & 6 & 4 & 28 \\ 0 & 5 & 10 & 10 & 30 \\ 0 & 0 & 0 & 24 & 71 \end{array} \right)$$
> $$\left( \begin{array}{cccc|c} 1 & 0 & 2.5 & 0 & 4 \\ 0 & 1 & 2 & 0 & 0 \\ 0 & 0 & 0 & 1 & 3 \end{array} \right)$$
> Легко заметить, что если в результате один из лидеров попал в столбец свободных членов, то система *несовместна*, поскольку одно из её уравнений будет иметь вид $$0x_1 + 0x_2 + \dots + 0x_n = c \neq 0 $$
> и, очевидно, не будет иметь решений. Такое уравнение также иногда называется *экзотическим*.

> **Шаг 2 (обратный ход)**
> 
> Назовём все переменные, входящие в базисный минор (иными словами, соответствующие лидерам строк), *главными*, а все остальные — *свободными*.
> Обратный ход метода Гаусса заключается в последовательном выражении главных переменных переменных через свободные, начиная с последних: $$\begin{cases} x_4 = 3 \\ x_2 = -x_3 \\ x_1 = -2.5 x_3 + 4 \end{cases}$$

## Следствия из метода Гаусса

Из метода Гаусса можно вывести несколько важных общих свойств СЛАУ:

> **Следствие 1**
> 
> СЛАУ совместна тогда и только тогда, когда после приведения её расширенной матрицы к ступенчатому виду в столбце свободных членов нет лидеров строк.

> **Следствие 2**
> 
> СЛАУ определена тогда и только тогда, когда после приведения к ступенчатому виду её матрица коэффициентов строго ступенчата.

> **Следствие 3**
> 
> Любая СЛАУ либо несовместна, либо определена, либо не определена.

> **Следствие 4**
> 
> Если число уравнений в СЛАУ меньше числа неизвестных, то она либо несовместна, либо не определена.
> 
> В частности, если число уравнений в однородной СЛАУ меньше числа неизвестных, то она имеет бесконечно много ненулевых решений.

---

# Вид множества решений СЛАУ

##  Фундаментальная система решений

>  **Теорема 2**
>  
>  Множество решений СЛАУ с $n$ неизвестными есть подпространство $\mathbb{R}^n$ тогда и только тогда, когда она однородна.
>  
>  **Доказательство**
>  
>  *Необходимость*. Если множество $U$ решений СЛАУ является подпространством в $\mathbb{R}^n$, то, по определению, нулевой вектор должен являться решением системы, что возможно лишь в ситуации, когда система однородна, что и требовалось доказать.
>  
>  *Достаточность*. Пусть система однородна. Если она имеет единственное — нулевое — решение, множество $U$ всех её решений будет удовлетворять определению подпространства. 
>  Иначе рассмотрим два набора $(x_1, x_2, \dots, x_n)$ и $(y_1, y_2, \dots, y_n)$, являющихся решениями системы. Для любых $\lambda_1, \lambda_2 \in \mathbb{R}$ имеем: $$\begin{gathered} \lambda_1(x_1, x_2, \dots, x_n) + \lambda_2(y_1, y_2, \dots, y_n) = (\lambda_1x_1 + \lambda_2y_1, \dots, \lambda_1x_n + \lambda_2y_n) \end{gathered}$$
>  Подставив получившиеся значения в произвольное уравнение исходной системы, получим: $$a_{i1}(\lambda_1x_1 + \lambda_2x_2) + \dots + a_{in}(\lambda_1x_n + \lambda_2y_n) = \lambda_1(a_{i1}x_1 + \dots + a_{in}x_n) + \lambda_2(a_{i1}y_1 + \dots + a_{in}y_n) $$
>  Поскольку исходные наборы являлись решениями системы, значение этого выражения будет равно $0$. Иными словами, линейная комбинация двух решений также является решением, а значит, что множество решений однородной СЛАУ является подпространством в $\mathbb{R}^n$, что и требовалось доказать.
>  
>  *Замечание*. Очевидно, что решения СЛАУ всегда принадлежат $\mathbb{R}^n$, поскольку являют собой не что иное, как $n$-ки вещественных чисел.

> **Теорема, обратная к теореме 2**
> 
> Любое подпространство в $\mathbb{R}^n$ является решением однородной системы уравнений.
> 
> **Доказательство**
> 
> Рассмотрим произвольное подпространство $U \subseteq V$. Обозначим $\dim V = n, \dim U = k$.
> 
> Рассмотрим произвольный базис $S$ подпространства $U$: $$S = \{u_1, \dots, u_k\}$$
> Дополним его до базиса $B$ пространства $V$: $$B = \{u_1, \dots, u_k, ~ v_{k+1}, \dots, v_{n}\} $$
> Рассмотрим произвольный вектор $v \in V$. Обозначим $x = [v]_E, y = [v]_B$. Заметим, что $B$ — матрица перехода из стандартного базиса $E$ к базису $V$; тогда $$\begin{aligned} &x = By & y = B^{-1}x \end{aligned} \tag{1}$$
> 
> Разложение $v$ по базису $B$ имеет вид: $$y = \sum\limits_{i = 1}^k \alpha_iu_i + \sum\limits_{i = k + 1}^n\beta_iv_i $$
> Ключевое замечание заключается в том, что $$v \in U \iff \forall k + 1 \leq i \leq n: \beta_i = 0 \tag{2}$$
> Рассмотрим матрицу $P = \{O~|~I\}$, где $O$ — нулевая матрица размером $n - k \times k$, $I$ — единичная матрица размерностью $n - k$: $$P = \left(\begin{array}{ccc|ccc} 0 & \dots & 0 & 1 & \dots & 0 \\ \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & \dots & 0 & 0 & \dots & 1\end{array}\right)$$
> Заметим, что условие $(2)$ эквивалентно $Py = 0$. Подставив $(1)$, имеем $$v \in U \iff PB^{-1}x = 0 $$
> Обозначив $A = PB^{-1}$, получим систему из $n-k$ уравнений с $n$ неизвестными, множество решений которой задаёт подпространство $U$, что и требовалось доказать.


> [!Info]
> Произвольный базис в пространстве решений однородной СЛАУ называется её **фундаментальной системой решений** (ФСР).

> **Лемма 1**
> 
> Размерность пространства решений однородной СЛАУ равна числу свободных неизвестных.
> 
> **Доказательство**
> 
> Пусть $x_{i_1}, x_{i_2}, \dots, x_{i_k}, 1 \leq i_1 < \dots < i_k \leq n$ — свободные переменные.
> Подставим вместо них координаты стандартного базиса в $\mathbb{R}^k$ и получим $k$ решений: $$\begin{gathered} (x_1^1, x_2^1, \dots, x_n^1) \\ \\(x_1^2, x_2^2, \dots, x_n^2) \\ \\  \dots \\ \\ (x_1^k, x_2^k, \dots, x_n^k) \end{gathered}$$
> Покажем, что они образуют ФСР.
> Рассмотрим произвольную нулевую линейную комбинацию этих векторов: $$\begin{gathered} \lambda_1(x_1^1, x_2^1, \dots, x_n^1) + \dots + \lambda_k(x_1^k, x_2^k, \dots, x_n^k) = 0 \end{gathered}$$
> В результирующем векторе $i_k$-я координата будет равна $\lambda_k$, поскольку во всех слагаемых, кроме $i_k$-го, соответствующая координата равна $0$, в то время как в самом $i_k$-м она равна $1$ — это немедленно следует из построение векторов. Отсюда сразу же видно, что результирующий вектор может быть нулевым тогда и только тогда, когда все $\lambda_k$ равны $0$. Иными словами, получившаяся система решений линейно независима.
> 
> Теперь рассмотрим произвольное решение исходной СЛАУ $(x_1^0, x_2^0, \dots, x_n^0)$. Покажем, что $$(x_1^0, x_2^0, \dots, x_n^0) = x_{i_1}^0(x_1^1, x_2^1, \dots, x_n^1) + \dots + x_{i_k}^0(x_1^k, x_2^k, \dots, x_n^k) $$
> В левой и правой части значения координат $i_1, i_2, \dots, i_k$ совпадают, при этом все остальные однозначно выражаются через них и, соответственно, также совпадают. Мы показали, что любое решение решение выражается как линейная комбинация рассмотренной системы, а значит, что она полна и, будучи также линейно независимой, является базисом, что и требовалось доказать.
> 
> *Следствие*. Количество свободных переменных не зависит от их выбора.

## Общий вид множества решений СЛАУ

> **Теорема 2**
> 
> Множество решений совместной СЛАУ является линейным подмногообразием $\mathbb{R}^n$.
> 
> **Доказательство**
> 
> Рассмотрим произвольную СЛАУ: $$\begin{cases} a_{11}x_1 + \dots + a_{1n}x_n = b_1 \\ \\ ~~~~~~~~~~~~~~~~~~\dots \\ \\ a_{m1}x_1 + \dots + a_{mn}x_n = b_m \end{cases} \tag{1}$$
> Построим *ассоциированную однородную систему*, т.е. положим все $b_i$ равными $0$: $$\begin{cases} a_{11}x_1 + \dots + a_{1n}x_n = 0 \\ \\ ~~~~~~~~~~~~~~~~~~\dots \\ \\ a_{m1}x_1 + \dots + a_{mn}x_n = 0 \end{cases} \tag{2}$$
> Зафиксируем произвольное решение $v$ системы $(1)$. 
> Мы хотим показать, что если $w$ и $u$ — произвольные решения $(1)$ и $(2)$ соответственно, то:
> 1. $v + u$ — решение $(1)$.
>    Пусть $v = (x_1, x_2, \dots, x_n), u = (y_1, y_2, \dots, y_n)$. Имеем: $$v + u = (x_1 + y_1, x_2 + y_2, \dots, x_n + y_n)$$
>    Подставив получившиеся значения в произвольное уравнение исходной системы, получим $$\begin{gathered} a_{i1}(x_1 + y_1) + a_{i2}(x_2 + y_2) + \dots + a_{in}(x_n + y_n) = \\ \\ = (a_{i1}x_1 + a_{i_2}x_2 + \dots + a_{in}x_n) + (a_{i1}y_1 + a_{i2}y_2 + \dots + a_{in}y_n) \end{gathered}$$
>    Поскольку набор $u$ являлся решением ассоциированной однородной системы, второе слагаемое будет равно $0$, и сумма наборов будет равна просто набору $v$, который по условию являлся решением исходной системы.
>    
> 2. $w - v$ — решение $(2)$
>    Пусть $w = (x_1, x_2, \dots, x_n), v = (y_1, y_2, \dots, y_n)$. Имеем: $$w - v = (x_1 - y_1, x_2 - y_2, \dots, x_n - y_n)$$
>    Подставив получившиеся значения в произвольное уравнение исходной системы, получим $$\begin{gathered} a_{i1}(x_1 - y_1) + a_{i2}(x_2 - y_2) + \dots + a_{in}(x_n - y_n) = \\ \\ = (a_{i1}x_1 + a_{i_2}x_2 + \dots + a_{in}x_n) - (a_{i1}y_1 + a_{i2}y_2 + \dots + a_{in}y_n) \end{gathered} $$
>    Поскольку оба набора являлись решениями исходного уравнения, значения обоих сумм совпадают, а значит, что разность наборов равняется $0$, т.е. является решением ассоциированной системы.
> 
> Таким образом, любое решение $w$ всегда имеет вид $v + u$, где $v$ — любое другое решение, а $u$ принадлежит подпространству $U$ решений ассоциированной однородной системы. Иными словами, множество решений совместной СЛАУ представляет собой линейное многообразие по подпространству $U$ и вектору $v$, что и требовалось доказать.

---
# Критерии совместности и определённости СЛАУ

> **Теорема Кронекера-Капелли**
> 
> СЛАУ совместна тогда и только тогда, когда ранги матрицы коэффициентов и расширенной матрицы совпадают.
> 
> **Доказательство**
> 
> Пусть $A$ — матрица коэффициентов СЛАУ,  $\tilde{A}$ — её расширенная матрица.
> Рассмотрим следующую цепочку эквивалентностей: $$\begin{aligned} \text{rk}~A = \text{rk}~\tilde{A} & \iff \dim\left<\begin{pmatrix} a_{11} \\ a_{21} \\ \dots \\ a_{m1}\end{pmatrix}, \dots, \begin{pmatrix} a_{1n} \\ a_{2n} \\ \dots \\ a_{mn}\end{pmatrix}\right> = \dim\left<\begin{pmatrix} a_{11} \\ a_{21} \\ \dots \\ a_{m1}\end{pmatrix}, \dots, \begin{pmatrix} a_{1n} \\ a_{2n} \\ \dots \\ a_{mn}\end{pmatrix}, \begin{pmatrix} b_{1} \\ b_{2} \\ \dots \\ b_{m}\end{pmatrix}\right> \iff \\ \\ & \stackrel{\begin{gathered} \text{т. о размерности} \\ \text{подпространства} \end{gathered}} \iff \left<\begin{pmatrix} a_{11} \\ a_{21} \\ \dots \\ a_{m1}\end{pmatrix}, \dots, \begin{pmatrix} a_{1n} \\ a_{2n} \\ \dots \\ a_{mn}\end{pmatrix}\right> = \left<\begin{pmatrix} a_{11} \\ a_{21} \\ \dots \\ a_{m1}\end{pmatrix}, \dots, \begin{pmatrix} a_{1n} \\ a_{2n} \\ \dots \\ a_{mn}\end{pmatrix}, \begin{pmatrix} b_{1} \\ b_{2} \\ \dots \\ b_{m}\end{pmatrix}\right> \iff \\ \\ & \stackrel{\begin{gathered} \text{лемма (5) о полных} \\ \text{системах} \end{gathered}}\iff \begin{pmatrix} b_{1} \\ b_{2} \\ \dots \\ b_{m}\end{pmatrix} = \lambda_1 \begin{pmatrix} a_{11} \\ a_{21} \\ \dots \\ a_{m1}\end{pmatrix} + \dots + \lambda_n \begin{pmatrix} a_{1n} \\ a_{2n} \\ \dots \\ a_{mn}\end{pmatrix} \end{aligned}$$
> Последнее тождество равносильно тому, что набор $\lambda_1, \lambda_2, \dots, \lambda_n$ является решением исходной системы. Поскольку все преобразования эквивалентны, доказана как достаточность, так и необходимость.

> **Критерий определённости СЛАУ**
> 
> СЛАУ с $n$ неизвестными определена тогда и только тогда, когда ранги матрицы коэффициентов и расширенной матрицы совпадают и равны $n$.
> 
> **Доказательство**
> 
> Пусть $A$ — матрица коэффициентов СЛАУ,  $\tilde{A}$ — её расширенная матрица.
> Если СЛАУ определена, то она совместна и не имеет свободных неизвестных, т.е. число строк в её ступенчатом виде совпадает с исходным. Иными словами, $$\text{rk}~A = \text{rk}~\tilde{A} = n, $$
> что и требовалось доказать.

---

# Метод Крамера

> **Теорема Крамера**
> 
> Определитель матрицы коэффициентов системы с одинаковым числом уравнений и неизвестных отличен от нуля тогда и только тогда, когда она определена. При этом также верно, что $$x_i = \frac{\det A(i)}{\det A}, $$
> где матрица $A(i)$ получена из исходной путём замены $i$-го столбца на столбец свободных коэффициентов.
> 
> **Доказательство**
> 
> Мы знаем, что $\det A \neq 0 \iff \text{rk}~A = n$. Ясно, что ранг расширенной матрицы не может превосходить ранг матрицы коэффициентов, поэтому имеем $\text{rk}~A = \text{rk}~A|B = n$, что удовлетворяет критерию определённости системы, поэтому первое утверждение теоремы доказано.
> 
> Пусть теперь $\det A \neq 0$. В этом случае матрица допускает приведение к единичному виду. 
> Проделав те же элементарные преобразования над матрицей $A(i)$, получим матрицу вида: $$\begin{pmatrix} 1 & 0 & \dots & b'_{1i} & \dots & 0 \\ 0 & 1 & \dots & b'_{2i} & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & b'_{mi} & \dots & 1  \end{pmatrix}$$
> От единичной матрицы она будет отличаться лишь, возможно, непосредственно $i$-м столбцом, поскольку его замена не повлияла ни на какие другие столбцы исходной матрицы.
> 
> Заметим, что при элементарных преобразованиях строк определители $\det A$ и $\det A(i)$ умножаются на одно и то же число, что значит, что их частное не изменяется. Таким образом, нам становится достаточно проверить корректность формул Крамера для следующей системы: $$\begin{cases}x_1 = b'_{1i} \\ x_2 = b'_{2i} \\ ~~~~ \dots \\x_n = b'_{ni} \end{cases},$$
> полученной на предыдущем этапе при помощи элементарных преобразований.
> В этом случае имеем $$x_j = \frac{\det E(j)}{\det E} $$
> По определению определителя легко показать, что $\det E(j) = b'_{ji}$, а значит, что $x_j = b'_{ji}$, что и требовалось доказать.